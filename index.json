[{"categories":[],"content":"Issue ID: (\u003c编号前缀\u003e-[A-Z\\d]+) Issue link: https://sentry.io/organizations/\u003c项目\u003e/issues/?query=$1 例： ","date":"2021-09-06","objectID":"/jetbrains-ide-%E9%85%8D%E7%BD%AE-sentry-issue-%E8%AF%86%E5%88%AB/:0:0","tags":[],"title":"Jetbrains IDE 配置 Sentry Issue 识别","uri":"/jetbrains-ide-%E9%85%8D%E7%BD%AE-sentry-issue-%E8%AF%86%E5%88%AB/"},{"categories":[],"content":"参考： Add Issue Navigation Link Dialog | IntelliJ IDEA Resolve a Short ID | Sentry Documentation What is a short ID? - Meta - #sentry ","date":"2021-09-06","objectID":"/jetbrains-ide-%E9%85%8D%E7%BD%AE-sentry-issue-%E8%AF%86%E5%88%AB/:0:1","tags":[],"title":"Jetbrains IDE 配置 Sentry Issue 识别","uri":"/jetbrains-ide-%E9%85%8D%E7%BD%AE-sentry-issue-%E8%AF%86%E5%88%AB/"},{"categories":["devops"],"content":"Rancher 监控面板出现 CPU 利用率出现负数 ","date":"2020-06-11","objectID":"/rancher-%E7%9B%91%E6%8E%A7%E9%9D%A2%E6%9D%BF%E5%87%BA%E7%8E%B0-cpu-%E5%88%A9%E7%94%A8%E7%8E%87%E5%87%BA%E7%8E%B0%E8%B4%9F%E6%95%B0/:1:0","tags":["Rancher","monitor","Prometheus","node_exporter"],"title":"Rancher 监控面板出现 CPU 利用率出现负数","uri":"/rancher-%E7%9B%91%E6%8E%A7%E9%9D%A2%E6%9D%BF%E5%87%BA%E7%8E%B0-cpu-%E5%88%A9%E7%94%A8%E7%8E%87%E5%87%BA%E7%8E%B0%E8%B4%9F%E6%95%B0/"},{"categories":["devops"],"content":"Rancher 监控面板是怎么工作的 Rancher 定义了三种 CRD 用于支持监控面板的展示： clustermonitorgraphs.management.cattle.io projectmonitorgraphs.management.cattle.io monitormetrics.management.cattle.io 其中前两个是类似的，只是工作的上下文不太一样，用于定义监控图表需要的监控指标，monitormetrics.management.cattle.io 存储了监控指标对应的 Prometheus 查询表达式。 以集群监控图表为例，API 为：/v3/clustermonitorgraphs?action=query，相关代码在：pkg/api/customization/monitor/cluster_graph_action.go#ClusterGraphHandler.QuerySeriesAction。 简单来说，基本逻辑就是 根据请求获取相关的 clustermonitorgraphs.management.cattle.io 根据指标名称拿到 monitormetrics.management.cattle.io，提取出查询表达式 根据请求参数和查询表达式得到真正的查询语句 请求 Prometheus 得到相关数据 转换成 API 响应并返回数据 ","date":"2020-06-11","objectID":"/rancher-%E7%9B%91%E6%8E%A7%E9%9D%A2%E6%9D%BF%E5%87%BA%E7%8E%B0-cpu-%E5%88%A9%E7%94%A8%E7%8E%87%E5%87%BA%E7%8E%B0%E8%B4%9F%E6%95%B0/:1:1","tags":["Rancher","monitor","Prometheus","node_exporter"],"title":"Rancher 监控面板出现 CPU 利用率出现负数","uri":"/rancher-%E7%9B%91%E6%8E%A7%E9%9D%A2%E6%9D%BF%E5%87%BA%E7%8E%B0-cpu-%E5%88%A9%E7%94%A8%E7%8E%87%E5%87%BA%E7%8E%B0%E8%B4%9F%E6%95%B0/"},{"categories":["devops"],"content":"CPU 利用率出现负数的原因 这里我们看一下出现问题的 CPU 利用率图表的相关对象。 API 请求： { \"filters\":{ \"resourceType\":\"node\", \"clusterId\":\"c-64wdm\" }, \"metricParams\":{ \"instance\":\"c-64wdm:machine-jf48v\" }, \"interval\":\"60s\", \"isDetails\":false, \"from\":\"now-1h\", \"to\":\"now\" } ➜ k get -n c-64wdm clustermonitorgraphs.management.cattle.io cluster-cpu-usage -o yaml apiVersion:management.cattle.io/v3kind:ClusterMonitorGraphmetadata:labels:app:metric-expressioncattle.io/creator:normancomponent:clusterlevel:clustersource:rancher-monitoringname:cluster-cpu-usagenamespace:c-64wdm...spec:clusterName:\"\"detailsMetricsSelector:component:clusterdetails:\"true\"metric:cpu-usage-seconds-sum-ratemetricsSelector:component:clusterdetails:\"false\"metric:cpu-usage-seconds-sum-ratepriority:100resourceType:clusteryAxis:unit:percent ➜ k get -n c-64wdm monitormetrics.management.cattle.io| grep cpu-usage-seconds-sum-rate cluster-cpu-usage-seconds-sum-rate 2d18h cluster-cpu-usage-seconds-sum-rate-details 2d18h cpu-usage-seconds-sum-rate-details 2d18h node-cpu-usage-seconds-sum-rate 2d18h node-cpu-usage-seconds-sum-rate-details 2d18h pod-cpu-usage-seconds-sum-rate 2d18h pod-cpu-usage-seconds-sum-rate-details 2d18h workload-cpu-usage-seconds-sum-rate 2d18h workload-cpu-usage-seconds-sum-rate-details 2d18h ➜ k get -n c-64wdm monitormetrics.management.cattle.io node-cpu-usage-seconds-sum-rate -o yaml apiVersion:management.cattle.io/v3kind:MonitorMetricmetadata:labels:app:metric-expressioncattle.io/creator:normancomponent:nodedetails:\"false\"level:clustermetric:cpu-usage-seconds-sum-ratesource:rancher-monitoringname:node-cpu-usage-seconds-sum-ratenamespace:c-64wdm...spec:description:nodecpuusagesecondssumrateexpression:1- (avg(irate(node_cpu_seconds_total{mode=\"idle\",instance=~\"$instance\"}[5m]))by(instance))legendFormat:CPU 可以看到 CPU 利用率最终的查询语句是 1 - (avg(irate(node_cpu_seconds_total{mode=\"idle\", instance=~\"$instance\"}[5m])) by (instance))，而这个查询表达式确实是可能产生负数值的，具体原因跟数据采样和 irate 函数有关。 首先，监控指标是 Prometheus 通过定时执行任务去数据源抓取的，node_exporter 的指标是不返回时间戳的，此时时间戳是抓取任务开始前取当前时间： scrape/scrape.go#L910 func (sl *scrapeLoop) run(interval, timeout time.Duration, errc chan\u003c- error) { ... mainLoop: for { ... var ( // 默认取任务开始时间为时间戳 start = time.Now() // 抓取任务可以配置超时时间 scrapeCtx, cancel = context.WithTimeout(sl.ctx, timeout) ) ... // 抓取数据 contentType, scrapeErr := sl.scraper.scrape(scrapeCtx, buf) cancel() ... // 写入数据 total, added, seriesAdded, appErr := sl.append(b, contentType, start) ... select { case \u003c-sl.parentCtx.Done(): close(sl.stopped) return case \u003c-sl.ctx.Done(): break mainLoop // 当定时器触发时继续执行抓取任务 case \u003c-ticker.C: } } ... } scrape/scrape.go#L1077 func (sl *scrapeLoop) append(b []byte, contentType string, ts time.Time) (total, added, seriesAdded int, err error) { var ( app = sl.appender() p = textparse.New(b, contentType) defTime = timestamp.FromTime(ts) appErrs = appendErrors{} sampleLimitErr error ) ... loop: for { var ( et textparse.Entry sampleAdded bool ) // 遍历数据 if et, err = p.Next(); err != nil { if err == io.EOF { err = nil } break } ... total++ t := defTime met, tp, v := p.Series() if !sl.honorTimestamps { tp = nil } // 如果使用数据源时间戳 if tp != nil { t = *tp } ... ce, ok := sl.cache.get(yoloString(met)) if ok { // 写入数据 err = app.AddFast(ce.ref, t, v) ... } ... added++ } ... } irate 函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率： promql/functions.go#L149 // === irate(node parser.ValueTypeMatrix) Vector === func funcIrate(vals []parser.Value, args parser.Expressions, enh *EvalNodeHelper) Vector { return instantValue(vals, enh.out, true) } ... func instantValue(vals []parser.Value, out Vector, isRate bool) Vector { samples := vals[0].(Matrix)[0] // No sense in trying to compute a rate without at least two points. Drop // this Vector element. if len(samples.Points) \u003c 2 { return out } // 取最后两个指标值 lastSample := samples.Points[len(samples.Points)-1] previousSample := samples.Points[len(samples.Points)-2] var resultValue float64 if isRate \u0026\u0026 lastSample.V \u003c previousSample.V { // Counter reset. resultValue = lastSample.V } else { // 最后两个指标值之差 r","date":"2020-06-11","objectID":"/rancher-%E7%9B%91%E6%8E%A7%E9%9D%A2%E6%9D%BF%E5%87%BA%E7%8E%B0-cpu-%E5%88%A9%E7%94%A8%E7%8E%87%E5%87%BA%E7%8E%B0%E8%B4%9F%E6%95%B0/:1:2","tags":["Rancher","monitor","Prometheus","node_exporter"],"title":"Rancher 监控面板出现 CPU 利用率出现负数","uri":"/rancher-%E7%9B%91%E6%8E%A7%E9%9D%A2%E6%9D%BF%E5%87%BA%E7%8E%B0-cpu-%E5%88%A9%E7%94%A8%E7%8E%87%E5%87%BA%E7%8E%B0%E8%B4%9F%E6%95%B0/"},{"categories":["devops"],"content":"最近在使用 Rancher 测试集群时流水线会偶发性的失败，提示 \"Error step Node not found\"，稍微搜索了一下在官方找到了一个 issue1，问题描述如下： 流水线分为多个阶段，每个阶段会有多个步骤同时进行，流水线执行时会有一定概率出现以下三种问题： \"Error WF Node for the step not found\" \"Error step Node not found\" \"Get http://10.43.219.169:8080/job/pipeline_p-jhz9s-528/lastBuild/wfapi/: net/http: request canceled (Client.Timeout exceeded while awaiting headers)\" 并提供了错误产生的代码位置： https://github.com/rancher/rancher/blob/0f081729cac35b18bdd7ff2922da4f9e0db7701c/pkg/pipeline/engine/jenkins/engine.go#L613 用户尝试了以下操作： 添加了一台 64GB 内存的机器 升级 Rancher 版本到 2.3.2 将发布阶段的多个步骤拆分到了多个阶段，不再并行执行 结果是错误仍然出现但概率降低了。 稍加分析，从这个 issue 能推断出哪些信息呢？ WHERE: 至少在 Rancher 2.3.2 问题仍然是存在的，并且有错误输出的代码位置 HOW: 添加机器，拆分流水线能降低问题发生概率降低了，问题可能和容器运行时的资源有关，比如 OOM 导致容器被杀死 WHEN: 有多种错误会出现，问题可能发生在不同的阶段 WHO: 外部请求失败，可能是流水线依赖的服务出现了问题 ","date":"2020-05-26","objectID":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/:0:0","tags":["Rancher","Jenkins"],"title":"Rancher 流水线随机失败问题","uri":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/"},{"categories":["devops"],"content":"Rancher 流水线基本概念和原理 流水线中的概念 流水线的工作原理 rancher 流水线基本上只是对 jenkins 进行简单的封装，基本原理如下： 通过授权拿到代码仓库信息，创建代码仓库 Webhook 用于触发流水线 流水线触发时 .rancher-pipeline.yml 流水线配置会被转换成 jenkins Pipeline 脚本 rancher server 通过 jenkins API 与 jenkins master 交互，创建 job jenkins master 创建 slave （buildpod）执行流水线 rancher server 通过 jenkins API 同步状态及日志 以下面的流水线配置为例： stages:- name:Stage1steps:- runScriptConfig:image:busyboxshellScript:|- echo \"this is stage 1 step 1\"- runScriptConfig:image:busyboxshellScript:|- echo \"this is stage 1 step 2\"- name:Stage2steps:- runScriptConfig:image:busyboxshellScript:|- echo \"this is stage 2 step 1\"- runScriptConfig:image:busyboxshellScript:|- echo \"this is stage 2 step 2\"timeout:60notification:{} 实际执行会被转换成如下 jenkins Pipeline 脚本： import org.jenkinsci.plugins.pipeline.modeldefinition.Utils def label = \"buildpod.${env.JOB_NAME}.${env.BUILD_NUMBER}\".replace('-', '_').replace('/', '_') podTemplate(label: label, instanceCap: 1, yaml: ''' apiVersion: v1 kind: Pod metadata: creationTimestamp: null labels: app: jenkins execution: p-dv8kn-5 namespace: p-f5pd2-pipeline spec: affinity: nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: - preference: matchExpressions: - key: pipeline.project.cattle.io/node operator: In values: - jenkins weight: 100 podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: labelSelector: matchExpressions: - key: app operator: In values: - jenkins topologyKey: kubernetes.io/hostname weight: 100 containers: - command: - cat env: ... image: rancher/pipeline-tools:v0.1.14 name: step-0-0 resources: limits: cpu: 300m memory: 100Mi requests: cpu: 10m memory: 10Mi tty: true ...x3... - args: - $(JENKINS_SECRET) - $(JENKINS_NAME) env: ... image: rancher/jenkins-jnlp-slave:3.35-4 name: jnlp resources: limits: cpu: \"1\" memory: 1Gi requests: cpu: 10m memory: 10Mi ... ''' ) { node(label) { timestamps { timeout(60) { stage('Clone'){ parallel 'step-0-0': { stage('step-0-0'){ container(name: 'step-0-0') { checkout([$class: 'GitSCM', branches: [[name: 'local/temp']], doGenerateSubmoduleConfigurations: false, extensions: [[$class: 'CloneOption', honorRefspec: true, noTags: false, reference: '', shallow: true]], userRemoteConfigs: [[url: 'http://gitlab.yzf.net/zhouerliang/pipeline-test.git', refspec: '+refs/heads/sample-pipeline:refs/remotes/local/temp', credentialsId: 'p-dv8kn-5']]]) } } } } stage('Stage1'){ parallel 'step-1-0': { stage('step-1-0'){ container(name: 'step-1-0') { sh ''' echo \"this is stage 1 step 1\" ''' } } },'step-1-1': { stage('step-1-1'){ container(name: 'step-1-1') { sh ''' echo \"this is stage 1 step 2\" ''' } } } } stage('Stage2') ... } } } } 注意这里 nodeAffinity，尽量选择标记了 jenkins 的节点，应当是对专门流水线节点的支持 podAntiAffinity，尽量将流水线的 pod 不放在一起，应当是因为 rancher/jenkins-jnlp-slave2 使用了 dind3，将 pod 打散避免执行阻塞住 另外，rancher 实际只是将 jenkins 服务作为执行引擎，不依赖任何 jenkins 存储任何执行记录，流水线相关的配置和执行记录通过 rancher 集群的 CRD 完成。 pipelineexecutions.project.cattle.io pipelines.project.cattle.io pipelinesettings.project.cattle.io 换句话说，jenkins master pod 重启会导致其 build 数据丢失，但不影响流水线记录数据。 下面的内容中，关于 jenkins 的一些概念这里也补充说明下： Workflow，其实就是 jenkins Pipeline 的曾用名 Node, node, agent 以及 slave 都用来指被 jenkins master 管理的用来执行 jenkins jobs 的服务器。主要区别是 agents 用在表述性pipeline中，可以不仅仅是 nodes，还可以是容器等， 而 node 用在脚本化pipeline中4。 ","date":"2020-05-26","objectID":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/:1:0","tags":["Rancher","Jenkins"],"title":"Rancher 流水线随机失败问题","uri":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/"},{"categories":["devops"],"content":"问题分析 func (j Engine) getStepLogFromJenkins(execution *v3.PipelineExecution, stage int, step int) (string, error) { if len(execution.Status.Stages) \u003c= stage || len(execution.Status.Stages[stage].Steps) \u003c= step { return \"\", errors.New(\"invalid step index\") } jobName := getJobName(execution) client, err := j.getJenkinsClient(execution) if err != nil { return \"\", err } info, err := client.getWFBuildInfo(jobName) if err != nil { return \"\", err } WFnodeID := \"\" for _, jStage := range info.Stages { if jStage.Name == fmt.Sprintf(\"step-%d-%d\", stage, step) { WFnodeID = jStage.ID break } } if WFnodeID == \"\" { return \"\", errors.New(\"Error WF Node for the step not found\") } WFnodeInfo, err := client.getWFNodeInfo(jobName, WFnodeID) if err != nil { return \"\", err } if len(WFnodeInfo.StageFlowNodes) \u003c 1 { return \"\", errors.New(\"Error step Node not found\") } logNodeID := WFnodeInfo.StageFlowNodes[0].ID logrus.Debugf(\"trying getWFNodeLog, %v, %v\", jobName, logNodeID) nodeLog, err := client.getWFNodeLog(jobName, logNodeID) if err != nil { return \"\", err } return nodeLog.Text, nil } 初始化 JenkinsClient 根据 jobName 获取 WFBuildInfo 遍历 WFBuildInfo 找到 WFnodeID 根据 WFnodeID 获取 WFnodeInfo 根据 WFnodeInfo 获取 logNodeID 根据 logNodeID 获取 nodeLog 可以看到这个接口基本上就是请求 jenkins master 服务，再不同的参数间转换直到拿到执行日志。 从报错的位置来看，\"Error WF Node for the step not found\"，\"Error step Node not found\" 这两种报错都是因为返回的数据异常导致的。 会不会是 jenkins 重启导致的呢？看一下工作负载，果然有一次重启。 p-sw6jr 是流水线出现问题的项目，从 jenkins build 记录来看，编号为 11 的记录丢失了： 这时候，看上去问题比较清晰了，jenkins 重启的时机不同会导致产生不同的错误。 当发出请求时，jenkins 正在重启，则出现请求失败，另外两种错误则是重启的时间不同产生的： ","date":"2020-05-26","objectID":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/:2:0","tags":["Rancher","Jenkins"],"title":"Rancher 流水线随机失败问题","uri":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/"},{"categories":["devops"],"content":"真的是这样吗？ 进一步浏览代码，发现 rancher 代码对从 jenkins 拿到的响应都是有检查的！ func checkHTTPError(resp *http.Response, event string) error { if resp == nil { return nil } if resp.StatusCode \u003c http.StatusOK || resp.StatusCode \u003e= http.StatusBadRequest { data, _ := ioutil.ReadAll(resp.Body) return httperror.NewAPIErrorLong(resp.StatusCode, fmt.Sprintf(\"%s got %d\", event, resp.StatusCode), string(data)) } return nil } 如果是重启后再去请求相关的数据，当数据不存在时会返回 404 状态码并被客户端检测到！如果请求时有任何错误或者响应状态码校验不通过都会直接导致报错。也就是说我们遇到的情况从逻辑上说有两种可能： 请求没有出错，响应不为空且状态码正常，但是没有返回相关字段的数据 请求没有出错，响应为空，此时相关的函数会返回空对象导致出错 对于第二种可能，通过阅读 http.Client 相关代码发现，只要请求没有出错，响应就一定不为空，那么也就是只有第一种可能，jenkins 服务返回了不完整的数据。 ","date":"2020-05-26","objectID":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/:3:0","tags":["Rancher","Jenkins"],"title":"Rancher 流水线随机失败问题","uri":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/"},{"categories":["devops"],"content":"问题复现 测试集群使用单台服务器，配置如图： 这里使用 2 个 stage，每个 stage 10 个 step 来进行测试，模拟多并发步骤，高负载的场景。 stages:- name:Buildsteps:- runScriptConfig:image:golang:1.14shellScript:|- go env -w GO111MODULE=ongoenv-wGOPROXY=https://goproxy.cn,directgoinstallgithub.com/gohugoio/hugo...x9...- name:Build2steps:- runScriptConfig:image:golang:1.14shellScript:|- go env -w GO111MODULE=ongoenv-wGOPROXY=https://goproxy.cn,directgoinstallgithub.com/gohugoio/hugo...x9...timeout:60notification:{} ","date":"2020-05-26","objectID":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/:4:0","tags":["Rancher","Jenkins"],"title":"Rancher 流水线随机失败问题","uri":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/"},{"categories":["devops"],"content":"使用重启 jenkins 的方式复现错误 这里使用杀死 jenkins 容器的方式做到让 pod 强制重启： kubectl exec -it [POD_NAME] -c [CONTAINER_NAME] -- /bin/sh -c \"kill 1\" 经过多次测试，大部分情况下会报连接不上 jenkins 服务的错误，在第 7 次时出现 \"Error step Node not found\"，看上去和实际情况不太一样，决定换一种复现方式。 ","date":"2020-05-26","objectID":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/:4:1","tags":["Rancher","Jenkins"],"title":"Rancher 流水线随机失败问题","uri":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/"},{"categories":["devops"],"content":"直接同时触发多个流水线复现错误 直接同时触发多个流水线后，果然多次出现了 \"Error step Node not found\"，同时 jenkins 服务也没有发生重启，证明 jenkins 服务重启并不是错误出现的必要条件。 拿到两次典型的流水线执行过程进行分析： PipelineExecution: p-wdg7z-24 p-wdg7z-24.yaml apiVersion:project.cattle.io/v3kind:PipelineExecutionmetadata:annotations:lifecycle.cattle.io/create.pipeline-execution-controller_c-vqqlf:\"true\"pipeline.project.cattle.io/local-registry-port:\"34153\"creationTimestamp:\"2020-06-01T06: 52: 40Z\"finalizers:- clusterscoped.controller.cattle.io/pipeline-execution-controller_c-vqqlfgeneration:15labels:cattle.io/creator:normanpipeline.project.cattle.io/finish:\"true\"name:p-wdg7z-24namespace:p-p4ls4...spec:...pipelineName:\"p-p4ls4:p-wdg7z\"projectName:\"c-vqqlf:p-p4ls4\"run:24time:\"Wed May 27 11: 05: 24 +0800 2020\"triggerUserName:user-765s2triggeredBy:userstatus:conditions:- lastUpdateTime:\"2020-06-01T06: 52: 46Z\"status:\"True\"type:Initialized- lastUpdateTime:\"2020-06-01T06: 53: 26Z\"message:\u003e- Running on buildpod.pipeline-p-wdg7z-24.1-knwj7-rg94z in/home/jenkins/agent/workspace/pipeline_p-wdg7z-24status:\"True\"type:Provisioned- lastUpdateTime:\"2020-06-01T06: 57: 21Z\"message:ErrorstepNodenotfoundreason:Errorstatus:\"False\"type:Builtended:\"2020-06-01T06: 57: 21Z\"executionState:Failedstages:- ended:\"2020-06-01T06: 50: 19Z\"started:\"2020-06-01T06: 50: 11Z\"state:Successsteps:- ended:\"2020-06-01T06: 50: 19Z\"started:\"2020-06-01T06: 50: 11Z\"state:Success- started:\"2020-06-01T06: 50: 21Z\"state:Buildingsteps:- ended:\"2020-06-01T06: 50: 21Z\"started:\"2020-06-01T06: 50: 21Z\"state:Success- ended:\"2020-06-01T06: 52: 37Z\"started:\"2020-06-01T06: 50: 21Z\"state:Success- started:\"2020-06-01T06: 50: 21Z\"state:Building- ended:\"2020-06-01T06: 53: 35Z\"started:\"2020-06-01T06: 50: 21Z\"state:Success- ended:\"2020-06-01T06: 53: 53Z\"started:\"2020-06-01T06: 50: 22Z\"state:Success- ended:\"2020-06-01T06: 53: 59Z\"started:\"2020-06-01T06: 50: 22Z\"state:Success- ended:\"2020-06-01T06: 53: 59Z\"started:\"2020-06-01T06: 50: 22Z\"state:Success- ended:\"2020-06-01T06: 54: 01Z\"started:\"2020-06-01T06: 50: 22Z\"state:Success- started:\"2020-06-01T06: 50: 22Z\"state:Building- ended:\"2020-06-01T06: 54: 07Z\"started:\"2020-06-01T06: 50: 23Z\"state:Success- state:Waitingsteps:- state:Waiting- state:Waiting- state:Waiting- state:Waiting- state:Waiting- state:Waiting- state:Waiting- state:Waiting- state:Waiting- state:Waitingstarted:\"2020-06-01T06: 52: 40Z\" package jenkins const ( ... JenkinsWFBuildInfoURI = \"/job/%s/lastBuild/wfapi\" JenkinsWFNodeInfoURI = \"/job/%s/lastBuild/execution/node/%s/wfapi\" JenkinsWFNodeLogURI = \"/job/%s/lastBuild/execution/node/%s/wfapi/log\" ... ) 使用代码中使用到的 API5 请求相关数据。 pipeline_p-wdg7z-24.json { \"_links\": { \"self\": { \"href\": \"/job/pipeline_p-wdg7z-24/lastBuild/wfapi/describe\" } }, \"id\": \"1\", \"name\": \"#1\", \"status\": \"ABORTED\", \"startTimeMillis\": 1590994179194, \"endTimeMillis\": 1590994452442, \"durationMillis\": 273248, \"queueDurationMillis\": 31, \"pauseDurationMillis\": 0, \"stages\": [ { \"_links\": { \"self\": { \"href\": \"/job/pipeline_p-wdg7z-24/lastBuild/execution/node/12/wfapi/describe\" } }, \"id\": \"12\", \"name\": \"Clone\", \"execNode\": \"\", \"status\": \"SUCCESS\", \"startTimeMillis\": 1590994211115, \"durationMillis\": 635, \"pauseDurationMillis\": 0 }, { \"_links\": { \"self\": { \"href\": \"/job/pipeline_p-wdg7z-24/lastBuild/execution/node/16/wfapi/describe\" } }, \"id\": \"16\", \"name\": \"step-0-0\", \"execNode\": \"\", \"status\": \"SUCCESS\", \"startTimeMillis\": 1590994211750, \"durationMillis\": 7551, \"pauseDurationMillis\": 0 }, { \"_links\": { \"self\": { \"href\": \"/job/pipeline_p-wdg7z-24/lastBuild/execution/node/29/wfapi/describe\" } }, \"id\": \"29\", \"name\": \"Build\", \"execNode\": \"\", \"status\": \"SUCCESS\", \"startTimeMillis\": 1590994219853, \"durationMillis\": 1165, \"pauseDurationMillis\": 0 }, { \"_links\": { \"self\": { \"href\": \"/job/pipeline_p-wdg7z-24/lastBuild/execution/node/51/wfapi/describe\" } }, \"id\": \"51\", \"name\": \"step-1-0\", \"execNode\": \"\", \"status\": \"SUCCESS\", \"startTimeMillis\": 1590994221018, \"durationMillis\": 224881, \"pauseDurationMillis\": 0 }, { \"_links\": { \"self\": { \"href\": \"/job/pipeline_p","date":"2020-05-26","objectID":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/:4:2","tags":["Rancher","Jenkins"],"title":"Rancher 流水线随机失败问题","uri":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/"},{"categories":["devops"],"content":"总结 结合找到的 jenkins issue 来看，根源问题应该是和 jenkins 在容器环境中高负载执行有关，具体原因因为深入到 jenkins 源码只能停留在此了。 但目前可以通过添加节点，将流水线并行的步骤拆分成多个阶段来缓解问题。 此外 rancher 在流水线这一块的代码，也可以有一些改进： \"Error step Node not found\" 错误可以带上 WFnodeID 便于定位问题 \"Error step Node not found\" 出现时并不代表 jenkins slave 执行失败了，但是流水线会将状态设置为 Failed，而 jenkins slave 仍然会继续执行，可能会有潜在的问题，rancher 在流水线失败时可以也执行清理逻辑6 buildpod 泄漏的情况需要能被检查和处理 Randomly getting the “Error step Node not found” exception #22478 ↩︎ rancher/jenkins-slave ↩︎ jpetazzo/dind ↩︎ Pipeline syntax overview ↩︎ Pipeline REST API Plugin ↩︎ https://github.com/rancher/rancher/blob/release/v2.3/pkg/controllers/user/pipeline/controller/pipelineexecution/pipelineexecution.go#L198 ↩︎ ","date":"2020-05-26","objectID":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/:5:0","tags":["Rancher","Jenkins"],"title":"Rancher 流水线随机失败问题","uri":"/rancher-%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%9A%8F%E6%9C%BA%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98/"},{"categories":["云原生"],"content":"背景 新公司服务在往 Kubernetes 上迁移，让我着手处理一个负载不均衡的问题，给到的描述是一个前台服务提供 API，后面挂两个 TensorFlow Model Server，其中后面的俩个服务存在负载不均衡的问题。 考虑到内部服务是基于 kube-proxy 的 L4 负载均衡，TensorFlow Model Server 是基于 gRPC 的，而 gRPC 是基于 HTTP2 的，第一反应是由于 HTTP2 连接复用导致的负载不均衡问题1，这里记录下验证过程和提供一些解决思路。 ","date":"2020-05-19","objectID":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:1:0","tags":["gRPC","Kubernetes"],"title":"gRPC 在 Kubernetes 中的负载均衡","uri":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["云原生"],"content":"验证假设 这里部署了一个 grpcbin2 服务用来测试 gRPC 服务的负载均衡： ghz/grpcbin.yaml apiVersion:v1kind:Servicemetadata:name:grpcbinspec:clusterIP:Noneports:- port:9000targetPort:9000selector:app:grpcbin---apiVersion:apps/v1kind:Deploymentmetadata:name:grpcbinlabels:app:grpcbinspec:replicas:3selector:matchLabels:app:grpcbintemplate:metadata:labels:app:grpcbinspec:dnsPolicy:ClusterFirstcontainers:- name:appimage:moul/grpcbinports:- containerPort:9000resources:requests:memory:50Micpu:\"1\"limits:memory:50Micpu:\"1\" 其中 resource QoS class3 设置为 Guaranteed， 确保 POD 资源是稳定的。 为了方便测试，这里使用 NodePort 类型的 Service 暴露出服务。不影响 kube-proxy 对服务的负载均衡。 测试客户端使用 ghz4，一个用于 gRPC 压力测试的工具，配置如下： ghz/Dockerfile FROMubuntu:bionicWORKDIR/appADD ghz-linux-x86_64.tar.gz .COPY grpcbin.proto .RUN chown -Rv root:root .ENTRYPOINT [ \"./ghz\" ] ghz/ghz.yaml apiVersion:v1kind:ConfigMapmetadata:name:ghz-configdata:config.toml:|- host = \"grpcbin:9000\"proto=\"grpcbin.proto\"call=\"grpcbin.GRPCBin.DummyUnary\"insecure=true# Number of connections to use.# Concurrency is distributed evenly among all the connections.# Default is 1.connections=1# Keepalive time duration. Only used if present and above 0.keepalive=0# Duration of application to send requests.# When duration is reached, application stops and exits.# If duration is specified, n is ignored. Examples: -z 10s -z 3m.duration=\"3m\"# Number of requests to run. Default is 200.total=1000000000# Number of requests to run concurrently.# Total number of requests cannot be smaller than the concurrency level.# Default is 50.concurrency=200# Rate limit, in queries per second (QPS). Default is no rate limit.qps=0[data]f_strings=[\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\",\"1234567890\"]---apiVersion:v1kind:Podmetadata:name:ghzlabels:app:ghzspec:volumes:- name:ghz-configconfigMap:name:ghz-configcontainers:- name:appimage:\"test/ghz:latest\"imagePullPolicy:Alwaysargs:[\"--config\",\"/etc/ghz/config.toml\",\"--debug\",\"/var/lib/ghz.json\"]volumeMounts:- mountPath:\"/etc/ghz\"name:ghz-configrestartPolicy:Never ","date":"2020-05-19","objectID":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:2:0","tags":["gRPC","Kubernetes"],"title":"gRPC 在 Kubernetes 中的负载均衡","uri":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["云原生"],"content":"使用 1 个连接进行测试 ➜ kubectl top pod NAME CPU(cores) MEMORY(bytes) grpcbin-7556ccbccb-rp6m9 0m 6Mi grpcbin-7556ccbccb-v2pgq 861m 10Mi grpcbin-7556ccbccb-wdpbq 0m 6Mi 运行稳定后可以看到只有 grpcbin-7556ccbccb-v2pgq 这个 POD 有负载。 ","date":"2020-05-19","objectID":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:2:1","tags":["gRPC","Kubernetes"],"title":"gRPC 在 Kubernetes 中的负载均衡","uri":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["云原生"],"content":"使用 3 个连接进行测试 ➜ kubectl top pod NAME CPU(cores) MEMORY(bytes) grpcbin-7556ccbccb-rp6m9 357m 9Mi grpcbin-7556ccbccb-v2pgq 518m 10Mi grpcbin-7556ccbccb-wdpbq 0m 6Mi 运行稳定后可以看到 grpcbin-7556ccbccb-rp6m9，grpcbin-7556ccbccb-v2pgq 这两个 POD 负载接近 1:2，即两者连接数分别为 1 和 2，这是因为集群 kube-proxy 使用的模式是 iptables，连接负载策略是随机的。 ","date":"2020-05-19","objectID":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:2:2","tags":["gRPC","Kubernetes"],"title":"gRPC 在 Kubernetes 中的负载均衡","uri":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["云原生"],"content":"解释 官方对 kube-proxy 的特点总结很清晰5： The kube proxy: runs on each node # 运行在每个节点 proxies UDP, TCP and SCTP # 可以代理UDP、TCP、SCTP协议 does not understand HTTP # 但是不能识别HTTP协议 provides load balancing # 提供负载均衡 is just used to reach services # 只用于到达服务 也就是说： kube-proxy 是一个 L4 负载均衡器，只支持连接级别负载均衡； gRPC 传输协议基于 HTTP2，使用了连接复用特性，客户端一般只会持有一个连接； 因此当连接建立后，后续的请求只会发送到该连接对应的节点。 ","date":"2020-05-19","objectID":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:3:0","tags":["gRPC","Kubernetes"],"title":"gRPC 在 Kubernetes 中的负载均衡","uri":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["云原生"],"content":"解决方案 ","date":"2020-05-19","objectID":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:4:0","tags":["gRPC","Kubernetes"],"title":"gRPC 在 Kubernetes 中的负载均衡","uri":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["云原生"],"content":"使用客户端负载均衡器 使用 Headless Service6，通过 DNS 直接返回一组 POD 地址； gRPC 的客户端代码使用提供的负载均衡功能7，同时使用 DNS Resolver 8实现客户端负载均衡器。 这种方案能够在不改变集群网络架构的情况下支持 gRPC 的负载均衡，但是还是有一些缺陷： 使用 Headless Service 和 DNS Resolver 会增大　CoreDNS 的压力； DNS Resolver 会有缓存，对服务的节点变化不够迅速； 方案有侵入性且适用性差。 ","date":"2020-05-19","objectID":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:4:1","tags":["gRPC","Kubernetes"],"title":"gRPC 在 Kubernetes 中的负载均衡","uri":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["云原生"],"content":"验证客户端负载均衡器方案 服务端测试代码及部署配置： load_balancing/server/main.go package main import ( \"context\" \"fmt\" \"log\" \"net\" \"os\" \"google.golang.org/grpc\" pb \"google.golang.org/grpc/examples/features/proto/echo\" ) type echoServer struct { pb.UnimplementedEchoServer hostname string } func (s *echoServer) UnaryEcho(ctx context.Context, req *pb.EchoRequest) (*pb.EchoResponse, error) { log.Println(\"received request:\", req.Message) return \u0026pb.EchoResponse{Message: fmt.Sprintf(\"(from %s): reply %s \", s.hostname, req.Message)}, nil } func main() { hostname, err := os.Hostname() if err != nil { log.Fatalf(\"failed to get hostname: %v\", err) } addr := \":9000\" lis, err := net.Listen(\"tcp\", addr) if err != nil { log.Fatalf(\"failed to listen: %v\", err) } s := grpc.NewServer() pb.RegisterEchoServer(s, \u0026echoServer{hostname: hostname}) log.Printf(\"serving on %s\\n\", addr) if err := s.Serve(lis); err != nil { log.Fatalf(\"failed to serve: %v\", err) } } load_balancing/server/deploy.yaml apiVersion:v1kind:Servicemetadata:name:echo-serverspec:clusterIP:None# 使用 Headless Serviceports:- port:9000targetPort:9000selector:app:echo-server---apiVersion:apps/v1kind:Deploymentmetadata:name:echo-serverlabels:app:echo-serverspec:replicas:3selector:matchLabels:app:echo-servertemplate:metadata:labels:app:echo-serverspec:dnsPolicy:ClusterFirstcontainers:- name:appimage:test/load_balancing_test:latestports:- containerPort:9000command:[\"./echo_server\"] 客户端测试代码及部署配置： load_balancing/client/main.go package main import ( \"context\" \"fmt\" \"log\" \"os\" \"time\" \"google.golang.org/grpc\" \"google.golang.org/grpc/balancer/roundrobin\" ecpb \"google.golang.org/grpc/examples/features/proto/echo\" ) func main() { target := os.Getenv(\"ECHO_SERVER\") if target == \"\" // 使用 dns 解析器 target = \"dns:///echo-server:9000\" } log.Println(\"target:\", target) // 建立连接 ctx, _ := context.WithTimeout(context.Background(), 3*time.Second) conn, err := grpc.DialContext( ctx, target, grpc.WithBlock(), grpc.WithInsecure(), // 负载均衡策略 grpc.WithBalancerName(roundrobin.Name), ) if err != nil { log.Fatalf(\"did not connect: %v\", err) } client := ecpb.NewEchoClient(conn) // 1 秒请求一次 messageID := 0 for range time.Tick(1*time.Second){ messageID++ ctx, _ := context.WithTimeout(context.Background(), 3*time.Second) response, err := client.UnaryEcho(ctx, \u0026ecpb.EchoRequest{Message: fmt.Sprintf(\"message %d\", messageID)}) if err != nil { log.Fatalf(\"could not send request: %v\", err) } log.Println(response.Message) } } load_balancing/client/deploy.yaml ---apiVersion:apps/v1kind:Deploymentmetadata:name:load-balancing-clientlabels:app:load-balancing-clientspec:replicas:1selector:matchLabels:app:load-balancing-clienttemplate:metadata:labels:app:load-balancing-clientspec:dnsPolicy:ClusterFirstcontainers:- name:appimage:test/load_balancing_test:latestcommand:[\"./load_balancing_client\"] 客户端测试代码使用 DNS 解析服务器地址，并使用 roundrobin 负载均衡策略。 我们首先测试的是设置 clusterIP: None 的情况（即使用 Headless Service），可以看到客户端输出的日志是符合预期的，请求会轮询服务器连接： 2020/05/25 07:12:45 target: dns:///echo-server:9000 2020/05/25 07:12:46 (from echo-server-866cff6884-66kj8): reply message 1 2020/05/25 07:12:47 (from echo-server-866cff6884-967bx): reply message 2 2020/05/25 07:12:48 (from echo-server-866cff6884-xsds5): reply message 3 2020/05/25 07:12:49 (from echo-server-866cff6884-66kj8): reply message 4 2020/05/25 07:12:50 (from echo-server-866cff6884-967bx): reply message 5 2020/05/25 07:12:51 (from echo-server-866cff6884-xsds5): reply message 6 当取消设置 clusterIP: None 后再重新部署客户端，此时客户端只能利用到一个服务器连接， 2020/05/25 07:14:02 target: dns:///echo-server:9000 2020/05/25 07:14:03 (from echo-server-6dcb87cb69-ws2gf): reply message 1 2020/05/25 07:14:04 (from echo-server-6dcb87cb69-ws2gf): reply message 2 2020/05/25 07:14:05 (from echo-server-6dcb87cb69-ws2gf): reply message 3 2020/05/25 07:14:06 (from echo-server-6dcb87cb69-ws2gf): reply message 4 2020/05/25 07:14:07 (from echo-server-6dcb87cb69-ws2gf): reply message 5 2020/05/25 07:14:08 (from echo-server-6dcb87cb69-ws2gf): reply message 6 也就是说 gRPC 客户端基于 DNS 解析的负载均","date":"2020-05-19","objectID":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:4:2","tags":["gRPC","Kubernetes"],"title":"gRPC 在 Kubernetes 中的负载均衡","uri":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["云原生"],"content":"使用服务端负载均衡器 使用 L7 负载均衡器，例如 Linkerd, Envoy。如果条件允许的话，可以使用 istio 之类的服务网格产品。 ","date":"2020-05-19","objectID":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:4:3","tags":["gRPC","Kubernetes"],"title":"gRPC 在 Kubernetes 中的负载均衡","uri":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["云原生"],"content":"关于 kube-proxy 负载均衡策略 kube-proxy 支持三种模式10： usersapce: 用户空间内的负载均衡，负载均衡支持轮询策略，性能一般； iptables: 完全使用 iptables 实现相关功能，只支持随机负载均衡，性能较好； ipvs: 基于 ipvs 做负载均衡，使用 iptables 实现 Cluster IP，包过滤，SNAT 或 masquerade11，性能最好，支持较多负载均衡策略，默认是轮询，可通过 --ipvs-scheduler 参数配置。 关于是否有必要选择从 iptables 切换到 ipvs 模式，可以参考这两篇文章： Comparing kube-proxy modes: iptables or IPVS? 话说kubernetes网络疑难杂症 基本结论是： 集群服务超过 1000 个时，使用 ipvs 能获得较明显的性能提升，具体数值取决于集群实际情况，但如果主要使用长连接的服务，使用 ipvs 的效果提升是有限的。 ipvs 模式下线规则时候的一个 bug，会导致新连接发送到已经下线的POD内，如果无法接受就需要等官方修复。 ","date":"2020-05-19","objectID":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:5:0","tags":["gRPC","Kubernetes"],"title":"gRPC 在 Kubernetes 中的负载均衡","uri":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["云原生"],"content":"如何在已经启动的集群修改 kube-proxy 配置 当然如果确定要将已上线的集群的 kube-proxy 模式设置为 ipvs 的话，这里也提供一些指引。 使用 kubeadm 安装： 集群管理 - 维护节点 kubeadm upgrade 使用 Rancher 安装： Rancher 2.x - 设置集群 使用 RKE 安装： RKE - How Upgrades Work gRPC Load Balancing on Kubernetes without Tears ↩︎ grpcbin ↩︎ QoS class ↩︎ ghz ↩︎ Proxies in Kubernetes ↩︎ Headless Service ↩︎ Load Balancing in gRPC，google.golang.org/grpc/balancer ↩︎ gRPC Name Resolution ↩︎ Dubbo的负载均衡 ↩︎ VIP 和 Service 代理 ↩︎ When IPVS falls back to IPTABLES ↩︎ ","date":"2020-05-19","objectID":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:5:1","tags":["gRPC","Kubernetes"],"title":"gRPC 在 Kubernetes 中的负载均衡","uri":"/grpc-%E5%9C%A8-kubernetes-%E4%B8%AD%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["Linux"],"content":"这几天在研究 Rancher 项目的源码，在准备开发环境的过程中发现其提供的 build 工具 dapper 输出帮助信息很奇怪，输出的程序名称竟然为 jetbrains-toolbox，第一反应是可能跟启动参数有关，随后开始了进一步调查。 在 IDEA 中显示的程序帮助： ","date":"2020-05-18","objectID":"/%E8%B2%8D%E7%8C%AB%E6%8D%A2%E5%A4%AA%E5%AD%90%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E8%B0%9C%E6%A1%88/:0:0","tags":[],"title":"貍猫换太子？程序启动参数谜案","uri":"/%E8%B2%8D%E7%8C%AB%E6%8D%A2%E5%A4%AA%E5%AD%90%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E8%B0%9C%E6%A1%88/"},{"categories":["Linux"],"content":"验证问题是否和启动参数有关 .dapper: @echo Downloading dapper @curl -sL https://releases.rancher.com/dapper/latest/dapper-`uname -s`-`uname -m` \u003e .dapper.tmp @@chmod +x .dapper.tmp @./.dapper.tmp -v @mv .dapper.tmp .dapper rancher 项目目录下生成的 .dapper 是在 Makefile 中下载下来的，并不是直接编译的， func main() { ... app := cli.NewApp() app.Author = \"Rancher Labs\" app.EnableBashCompletion = true app.Version = VERSION app.Usage = `Docker build wrapper ... dapper 使用 github.com/urfave/cli 这个包作为应用框架，代码中没有明确指定应用名称，看来应该是框架处理的， func NewApp() *App { return \u0026App{ Name: filepath.Base(os.Args[0]), HelpName: filepath.Base(os.Args[0]), Usage: \"A new cli application\", ... } } 果然，框架使用 filepath.Base(os.Args[0]) 作为默认的应用名称，看来确实因为启动参数的问题导致的输出错误。 ","date":"2020-05-18","objectID":"/%E8%B2%8D%E7%8C%AB%E6%8D%A2%E5%A4%AA%E5%AD%90%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E8%B0%9C%E6%A1%88/:1:0","tags":[],"title":"貍猫换太子？程序启动参数谜案","uri":"/%E8%B2%8D%E7%8C%AB%E6%8D%A2%E5%A4%AA%E5%AD%90%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E8%B0%9C%E6%A1%88/"},{"categories":["Linux"],"content":"是谁改变了启动参数呢 考虑到我是在 JetBrains Toolbox 启动的 IDEA，然后在 IDEA 启动的终端，可能是 JetBrains Toolbox 的某些环境变量一路传递到了终端里，我尝试着过滤了下可能的环境变量。 出现了可疑的环境变量，其中 APPIMAGE 看上去是和 Linux 应用的打包格式 AppImage 有关系，但是这两个环境变量看上去和 os.Args 没有什么关系，从 AppImage 文档 中了解到 AppImage 运行时会设置几个环境变量，其中有一个 ARGV0： ARGV0 Name/path used to execute the script. This corresponds to the value you’d normally receive via the argv argument passed to your main method. Usually contains the filename or path to the AppImage, relative to the current working directory. 看起来和它有关，把它删除掉看看有什么效果， 输出正常了！那为什么 ARGV0 会影响到终端程序的启动参数呢，难道这是一个通用的环境变量吗？再次祭出谷歌大法，找到个一个问题： Setting environmental variable ARGV0 cause some packed software malfunctioning #852 原来这是个已知问题，因为我使用的 shell 是 zsh，而 zsh 会使用 ARGV0 环境变量作为第一个参数执行程序。 http://zsh.sourceforge.net/Doc/Release/Parameters.html#Parameters-Used-By-The-Shell ARGV0 If exported, its value is used as the argv[0] of external commands. Usually used in constructs like ‘ARGV0=emacs nethack’. 到这里结论就很清晰了，将 IDEA 的默认 shell 改为 bash，ARGV0 仍然存在，但已经不会影响程序的输出了。 等等！一般来说 os.Args 第一个参数就是程序的路径，难道可以允许和实际程序路径不一样？ 这就得从 Linux 系统调用说起了，os.Args[0] 指代的是程序的名称，但这跟其他参数本质上没什么区别，并不要求一定是程序执行路径，具体信息可以参照下面两个链接，这里就不展开了。 Why does argv include the program name? EXEC(3) man page ","date":"2020-05-18","objectID":"/%E8%B2%8D%E7%8C%AB%E6%8D%A2%E5%A4%AA%E5%AD%90%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E8%B0%9C%E6%A1%88/:2:0","tags":[],"title":"貍猫换太子？程序启动参数谜案","uri":"/%E8%B2%8D%E7%8C%AB%E6%8D%A2%E5%A4%AA%E5%AD%90%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E8%B0%9C%E6%A1%88/"},{"categories":["Linux"],"content":"总结 AppImage 运行时会设置 ARGV0 环境变量，而 jetbrains-toolbox 使用的是 AppImage 打包； 从 jetbrains-toolbox 启动 IDEA 会复制父进程的环境变量； IDEA 使用的 shell 是 zsh，而 zsh 会使用 ARGV0 环境变量作为 os.Args[0]； os.Args[0] 是程序的名字，并不是必须的或者必须是实际程序路径。 ","date":"2020-05-18","objectID":"/%E8%B2%8D%E7%8C%AB%E6%8D%A2%E5%A4%AA%E5%AD%90%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E8%B0%9C%E6%A1%88/:3:0","tags":[],"title":"貍猫换太子？程序启动参数谜案","uri":"/%E8%B2%8D%E7%8C%AB%E6%8D%A2%E5%A4%AA%E5%AD%90%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E8%B0%9C%E6%A1%88/"},{"categories":["Linux"],"content":"补充问题 你们知道为什么当时过滤 jetbrains 环境变量为什么没有过滤出来 ARGV0 吗？ 提示，在 bash 下是可以过滤出来的： ","date":"2020-05-18","objectID":"/%E8%B2%8D%E7%8C%AB%E6%8D%A2%E5%A4%AA%E5%AD%90%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E8%B0%9C%E6%A1%88/:4:0","tags":[],"title":"貍猫换太子？程序启动参数谜案","uri":"/%E8%B2%8D%E7%8C%AB%E6%8D%A2%E5%A4%AA%E5%AD%90%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E8%B0%9C%E6%A1%88/"},{"categories":["Python"],"content":"Celery 作为 Python 世界中使用最广泛的分布式任务队列工具, 提供了非常方便灵活的配置方式, 但有时候也容易给人带来困扰, 这边文章从原理和代码出发, 来给大家讲明白 Celery 的任务是如何分发出去的. ","date":"2019-12-24","objectID":"/celery-%E6%98%AF%E5%A6%82%E4%BD%95%E8%B7%AF%E7%94%B1%E6%B6%88%E6%81%AF%E7%9A%84/:0:0","tags":["Celery","AMQP"],"title":"Celery 是如何路由消息的","uri":"/celery-%E6%98%AF%E5%A6%82%E4%BD%95%E8%B7%AF%E7%94%B1%E6%B6%88%E6%81%AF%E7%9A%84/"},{"categories":["Python"],"content":"高级消息队列协议(AMQP) 整个 Celery 是基于 AMQP 实现的, 了解 AMQP 是了解 Celery 如何将任务分发出去的前提. 这里推荐一篇文章 AMQP 0-9-1 Model Explained. 从这篇文章我们能得到有几个需要知道的重点: Queue 声明时会与 Exchange 进行 binding, 可能会 binding 多个 Exchange, 所有的消息发布时要带上 exchange 和 routine_key, 到达 Exchange 后, Exchange 根据 exchange_type 和 binding 分发消息至相应的队列. AMQP 的 Exchange 有四种类型, 每个类型都有预定义的 Exchange, 类型为 direct 且名称为空的 exchange 是一个默认的 Exchange, 所有的队列在创建时都会自动将队列名设置为 routing_key 并与该 exchange 进行绑定. ","date":"2019-12-24","objectID":"/celery-%E6%98%AF%E5%A6%82%E4%BD%95%E8%B7%AF%E7%94%B1%E6%B6%88%E6%81%AF%E7%9A%84/:1:0","tags":["Celery","AMQP"],"title":"Celery 是如何路由消息的","uri":"/celery-%E6%98%AF%E5%A6%82%E4%BD%95%E8%B7%AF%E7%94%B1%E6%B6%88%E6%81%AF%E7%9A%84/"},{"categories":["Python"],"content":"Celery 是怎么分发一个任务的 分发一个任务, 就是根据配置, 带上 exchange 和 routine_key 发送一条消息, 从代码层面, 注意分成两个阶段: Celery.send_task: 根据任务信息, 根据 task_routes 配置取路由, 然后构造消息, 调用 amqp.send_task_message https://github.com/celery/celery/blob/v4.3.0/celery/app/base.py#L723 options = router.route( options, route_name or name, args, kwargs, task_type) Celery.amqp.send_task_message: 处理默认的路由行为并发送消息 https://github.com/celery/celery/blob/v4.3.0/celery/app/amqp.py#L485 def send_task_message(producer, name, message, exchange=None, routing_key=None, queue=None, event_dispatcher=None, retry=None, retry_policy=None, serializer=None, delivery_mode=None, compression=None, declare=None, headers=None, exchange_type=None, **kwargs): retry = default_retry if retry is None else retry headers2, properties, body, sent_event = message if headers: headers2.update(headers) if kwargs: properties.update(kwargs) qname = queue if queue is None and exchange is None: queue = default_queue if queue is not None: if isinstance(queue, string_t): qname, queue = queue, queues[queue] else: qname = queue.name if delivery_mode is None: try: delivery_mode = queue.exchange.delivery_mode except AttributeError: pass delivery_mode = delivery_mode or default_delivery_mode if exchange_type is None: try: exchange_type = queue.exchange.type except AttributeError: exchange_type = 'direct' # convert to anon-exchange, when exchange not set and direct ex. if (not exchange or not routing_key) and exchange_type == 'direct': exchange, routing_key = '', qname elif exchange is None: # not topic exchange, and exchange not undefined # 当指定 `queue` 且 exchange type 等于 `direct`, # Celery 发送消息时会将 exchange 设置为空, 同时 routing_key 设置为队列名 # 这时候会利用到 AMQP 的 default exchange exchange = queue.exchange.name or default_exchange routing_key = routing_key or queue.routing_key or default_rkey ... ret = producer.publish( body, exchange=exchange, routing_key=routing_key, serializer=serializer or default_serializer, compression=compression or default_compressor, retry=retry, retry_policy=_rp, delivery_mode=delivery_mode, declare=declare, headers=headers2, **properties ) 可能有同学会问, 既然是处理默认的路由行为, 为什么没有使用到 task_default_exchange , task_default_queue, task_default_routing_key 这些配置呢? 答案在 Celery.amqp 加载队列的逻辑里, https://github.com/celery/celery/blob/v4.3.0/celery/app/amqp.py#L126 def _add(self, queue): if not queue.routing_key: if queue.exchange is None or queue.exchange.name == '': queue.exchange = self.default_exchange queue.routing_key = self.default_routing_key ... 当一个 Queue 加载的时候, 如果没有提供 exchange 和 routing_key, 会填充默认的配置. 但实际上一个 Queue 是可以有多个 binding 的, Queue.exchange, Queue.routing_key 只是提供的一个简便写法. Queue 的实例初始化函数如下: https://github.com/celery/kombu/blob/4.6.7/kombu/entity.py#L567 def __init__(self, name='', exchange=None, routing_key='', channel=None, bindings=None, on_declared=None, **kwargs): super(Queue, self).__init__(**kwargs) self.name = name or self.name if isinstance(exchange, str): self.exchange = Exchange(exchange) elif isinstance(exchange, Exchange): self.exchange = exchange self.routing_key = routing_key or self.routing_key self.bindings = set(bindings or []) self.on_declared = on_declared # allows Queue('name', [binding(...), binding(...), ...]) if isinstance(exchange, (list, tuple, set)): self.bindings |= set(exchange) if self.bindings: self.exchange = None # exclusive implies auto-delete. if self.exclusive: self.auto_delete = True self.maybe_bind(channel) 以上的行为会导致, 在没有 task_routes 配置的情况下, 当你的 task 指定了 queue , 但是 Queue 的定义没有设置 exchange, routing_key 属性, 可能就会导致不符合期望的行为. 关于指定 task 的路由, 可以参考官方文档 Specifying task destination. ","date":"2019-12-24","objectID":"/celery-%E6%98%AF%E5%A6%82%E4%BD%95%E8%B7%AF%E7%94%B1%E6%B6%88%E6%81%AF%E7%9A%84/:2:0","tags":["Celery","AMQP"],"title":"Celery 是如何路由消息的","uri":"/celery-%E6%98%AF%E5%A6%82%E4%BD%95%E8%B7%AF%E7%94%B1%E6%B6%88%E6%81%AF%E7%9A%84/"},{"categories":["云原生"],"content":"https://edu.aliyun.com/roadmap/cloudnative ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:0","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 1 讲：第一堂 “云原生” 课 3. (单选) 我编写的容器化应用，会将日志文件写在某路径写死的目录里。请问这破坏了云原生理念了吗 正确答案： B. 是 ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:1","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 2 讲：容器基本概念 5. 已运行 docker run -d -t —name demo ubuntu top 命令, 是否可以在 demo 这个容器内部停止容器 A. 是 B. 否 正确答案： B 8. 已运行 docker run -d -t —name demo ubuntu top 和 docker run –name demo-x –pid container:demo ubuntu ps 命令，是否可以在 demo-x 容器内部停止容器 A. 是 B. 否 正确答案： A ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:2","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 3 讲：Kubernetes 核心概念 3. Scheduler 的主要功能是________ A. Pod 的在 Node 上的放置 B. Pod 的生命周期管理 C. Node 上具体的资源分配 D. Node 的生命周期管理 正确答案： A 10. 属于 Node 上的基本组件有________ A. Kubelet B. Kube-proxy C. Controller Manager D. Container runtime engine 正确答案： A B D ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:3","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 4 讲：理解 Pod 和容器设计模式 3. 一个 Pod 里 Infra Container 的启动顺序是 A. 无所谓 B. 最后一个 C. 先于主业务容器启动即可 D. 第一个 正确答案： D 8. 如果没有 Pod 概念，但我要用多个容器模拟 Pod 的话，可能需要做哪些工作 A. resource hoarding B. 乐观调度 C. 共享这些容器的 Network Namespace D. 设置 Affinity 约束 正确答案： A B C D 9. 关于 Google Borg 论文论述正确的是 A. 应用互相之间往往相互独立，毫不相关 B. 应用互相之间往往存在协作关系 C. 很多应用需要部署永远部署在同一台机器上 D. Google 在进行应用开发的过程中，天生就具备微服务的概念 正确答案： B C D ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:4","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 5 讲：应用编排与管理 - 核心原理 1. Controller 中的 workerqueue 中可以存放什么内容 A. Namespace 名 + pod 名 B. Namespace 名 + pod 名 + 事件的类型 C. Pod 的列表 D. Pod 对象的指针 正确答案： A 2. Controller 中的 object store 默认以什么作为索引 A. 对象的 label B. 对象的 annotation C. 对象的 namespace D. 对象的名字 正确答案： C 7. 在 controller 的 event handler 中， 不适合执行的操作是 A. 根据资源的 ownerreference 找到资源的创建者 B. 判断资源信息，对于不关心的对象， 直接返回 C. 在 workqueue 中加入资源 D. 执行控制器的实际处理工作 正确答案： D 8. 下列关于 controller 中 workqueue 描述不正确的 A. 因为 workqueue 具备去重功能，可以往 workqueue 中反复加入资源 B. 为了加速 controller 的处理，可以往 workqueue 中加入资源的指针 C. 一个控制器的 workqueue 一般只存储一种类型资源的名字 D. 对于处理 node 的控制器，可以只在 workqueue 中加入节点的名字而不包括命名空间 正确答案： B 10. 以下不是声明式的 API 设计 A. 创建一个容器的 API 是 POST /containers/create，请求参数是容器的各种规格， 返回系统生成的容器 id B. 删除一个容器的 API 是 DELETE /containers/, 返回一个异步删除的工单号，可以根据工单号查询删除进度 C. 给应用扩容的 API 是 PUT /containers/create?increaseReplicas=1， 参数指定扩容的增量容器数量 D. 更新一个容器镜像的 API 是 PATCH /containers/?image=nginx, 返回的是容器新的目标状态 正确答案： A B C ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:5","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 6 讲：应用编排与管理 - Deployment 2. 关于 MaxUnavailable 以下说法正确的是： A. MaxUnavailable 不可以设置为 0，否则无法发布 B. MaxUnavailable 可以设置超过 replicas C. MaxUnavailable 可以和 MaxSurge 同时设置为 0 D. MaxUnavailable 可以设置超过 100% 正确答案： B 8. Deployment 与 ReplicaSet 的关系与以下哪组资源最像 A. Pod 与 Node B. Pod 与 Container C. ReplicaSet 与 Pod D. Deployment 与 Pod 正确答案： C 9. 以下关于 Deployment 的说法正确的有哪些 A. Deployment 下 running 的 Pod 数量可能大于 replicas 数量 B. Deployment 更新镜像时一定会创建一个 ReplicaSet C. 用 kubectl rollout undo 命令回滚 Deployment，不会创建新的 ReplicaSet D. 滚动发布的时候 MaxUnavailable 和 MaxSurge 可以同时设为 0 正确答案： A C 10. 指定 Deployment 回滚到某个历史版本执行成功的过程中，不会发生以下哪些事件： A. Pod 创建和销毁 B. ReplicaSet 创建和销毁 C. Deployment 期望数量变化 D. Deployment template 变化 正确答案： B C ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:6","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 7 讲：应用编排与管理 - Job 和 DaemonSet 9. 使用哪些标签能让 daemonset 的 pod 只运行在某些节点 A. .spec.template.spec.nodeSelector B. .spec.template.spec.affinity C. Taints and Tolerations D. matchExpressions 正确答案： A B A Pod Template in a DaemonSet must have a RestartPolicy equal to Always, or be unspecified, which defaults to Always. ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:7","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 8 讲：应用配置管理 6. 当节点磁盘空间不足时，Pod 被驱逐的顺序为: BestEffort 先于 Burstable 正确答案： 正确 10. 如下哪些方式创建的 Pod 可以使用 ConfigMap A. Kubectl B. Dashboard C. kubelet mainifests D. kubelet url 正确答案： A B ConfigMap 使用注意点 ConfigMap 文件大小限制：1MB（etcd 的要求） Pod 只能引用相同 Namespace 中的 ConfigMap 3．Pod 引用的 ConfigMap 不存在时，Pod 无法创建成功。即 Pod 创建前需要先创建好 ConfigMap 使用 envFrom 从 ConfigMap 来配置环境变量时，如果 ConfigMap 中的某些 key 被认为无效（比如 key 名称中带有数字），该环境变量将不会注入容器，但是 Pod 可以正常创建。 只有通过 k8s api 创建的 pod 才能使用 ConfigMap, 其他方式创建的 pod（如 manifest 创建的 pod) 不能使用 ConfigMap ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:8","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 9 讲：应用存储和持久化数据卷 - 核心知识 5. 在 Pod 中声明使用 volume 需要配置哪些字段 A. .spec.volumes B. .spec.initContainers.volumeMounts C. .spec.containers.volumeMounts 正确答案： A B C 6. 在 Pod 中声明使用 volume 常见类型 A. 本地存储 B. 网络存储 C. Projected Volume(投射卷) D. PVC+PV 持久化存储 正确答案： A B C D ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:9","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 10 讲：应用存储和持久化数据卷 - 存储快照与拓扑调度 3. 下面在 Kube-Scheduler 中结合 Pod 中声明的 PVCs 选择 Node 过程描述正确的有 A. Pod 中已经 Bound 的 PVCs 在 Kube-Scheduler 不做处理 B. Pod 中所有 UnBound 的 PVCs 会先找到能匹配的 PV 列表，并 check PV 的 NodeAffinity 与 Node Labals 中的拓扑信息是否匹配 C. Pod 中需要 Dynamic Provisioning PV 的 PVCs，check StorageClass .allowedTopologies 与 Node Labels 中的拓扑信息是否匹配 正确答案： C 4. Kubernetes 中为了支持存储拓扑调度相关组件做的改变有 A. PersistentVolumeController 支持 PVC 与 PV 的 delay binding B. 动态创建 PV 的 csi-provisioner 支持将第一个使用 PV 的 Pod 待运行 Node 的拓扑信息以及 StorageClass .allowedTopologies 传递给创建存储的 Driver C. Kube-Scheduler 结合 Pod 使用的 PVCs，预分配的 PV Node Affinity 以及 StorageClass .allowedTopologies 选择合适的 Node 正确答案： A B C 5. 下列有关使用存储拓扑调度时对 StorageClass 的配置正确的有 A. 需要通过设置. volumeBindingMode: WaitForFirstConsumer 来声明 PVC 延时处理 B. 可以通过. allowedTopologies 限制动态生成的 PV 的拓扑限制，拓扑限制会写到动态生成的 PV .spec.nodeAffinity 中 C. 可以干预哪些需要使用该 StorageClass 动态生成 PV 对象的 PVC 的使用方 Pod 的可调度的 Node 正确答案： A B C 7. 可以限制 PV 对象可被访问拓扑位置限制的地方 A. StorageClass: .allowedTopologies B. PV: .spec.nodeAffinity C. Node: .metadata.labels 正确答案： A B 8. 下列有关如何使用存储拓扑调度的说法正确的有 A. 声明 delay binding 的 StorageClass 对象（.volumeBindingMode=WaitForFirstConsumer） B. PVC 对象. spec.storageClassName 指定为声明了 delay binding 的 StorageClass 对象 C. 在静态（预）创建的 PV 上的. spec.nodeAffinity 添加对使用该 PV 的 Pod 所在 Node 拓扑限制 D. 在需要动态创建的 PV 所使用的 StorageClass 的. allowedTopologies 中限制动态创建的存储能被使用的拓扑限制 正确答案： A B C D 9. 使用存储快照功能需要用到哪些 Kubernetes API 资源对象 A. VolumeSnapshot B. VolumeSnapshotClass C. VolumeSnapshotContent D. PersistentVolumeClaim 正确答案： A B C D ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:10","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 11 讲：可观测性——你的应用健康吗 4. Readiness Probe 可以解决应用启动慢造成访问异常的问题。 正确 错误 正确答案： 正确 7. 当 Pod 处在 Pending 的时候，可能是由于如下哪个问题造成的。 A. 资源不足，造成无法调度 B. Pod 尚未进入调度阶段 C. Pod 调度失败 D. Pod 正在拉取镜像 正确答案： A B D 9. 以下哪个关于 Liveness Probe 的描述是错误的 A. Liveness Probe 是就绪探针 B. Liveness Probe 是存活探针 C. Livenss Probe 和 Readiness Probe 的探测方式是一致的 D. Liveness Probe 主要面向有状态服务 正确答案： A D ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:11","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 12 讲：可观测性——监控与日志 2. 以下哪个不是 Prometheus 的优势 A. Prometheus 的采集性能优越 B. Prometheus 的采集方式丰富 C. Prometheus 的接入方式简单 D. Prometheus 的插件丰富 正确答案： A ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:12","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 13 讲：Kubernetes 网络概念及策略控制 1. 影响容器网络性能最关键的因素是哪个 A. IP 地址管理方式 B. 是否使用隧道技术 C. 网络拓扑路径 D. 底层网络性能 正确答案： C 3. 哪种容器网络方案是普适性最高的默认选择 A. Flannel-vxLan B. Flannel-host gw C. Canal D. Calico 正确答案： A 5. net namespace 拥有完全独立隔离的网络环境。 正确 错误 正确答案： 错误 相关知识点： 不准确，协议栈代码是公用的，很多 systemctl 可控参数并没有独立 6. Kubernetes 的 Pod 只能有且只能配置 1 个 IP 地址。 正确 错误 正确答案： 错误 相关知识点： 不准确，可以有多个 IP 地址，只是上报给 CNI 结果时候，只能报一个 7. Kubernetes network policy 只支持 TCP/UDP 作为协议字段值。 正确 错误 相关知识点： 还支持 stcp（alpha 特性） 正确答案： 错误 8. Kubernetes 容器网络方案实现上，禁止任何形式的地址转换（NAT）。 正确 错误 相关知识点： 可以使用 NAT 作为实现手段，不能被 Pod-APP 感知 9. Kubernetes 基本网络模型需要符合哪些条件 A. 所有 Pod 可以与其他 Pod 直接通信，无需显式使用 NAT B. 所有 Node 可以与所有 Pod 直接通信，无需显式使用 NAT C. Pod 可见的 IP 地址确为其他 Pod 与其通信时所用，无需显式转换 正确答案： A B C 10. Kubernetes 网络方案需要考虑哪些需要达成的连通性目标 A. 容器与容器间的通信 B. Pod 与 Pod 之间的通信 C. Pod 与 Service 间的通信 D. 外部世界与 Service 间的通信 正确答案： A B C D ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:13","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 14 讲：Kubernetes Services 5. 创建 LoadBalancer 类型的 Service 会自动创建和绑定外部 LoadBalancer 到节点映射的 NodePort 上。 正确 错误 正确答案： 正确 8. Pod 可以直接用 Service 名来访问同一个集群里的 Service，不管 Pod 和 Service 在不在一个 Namespace。 正确 错误 正确答案： 错误 ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:14","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 15 讲：深入剖析 Linux 容器 3. docker 在宿主机上最多可以创建多少个容器 A. 1000 B. 和宿主机的 cpu/memory 资源有关系 C. 不一定 正确答案： C 4. 宿主机上能否看见容器内的进程 A. 不能，因为容器有自己的 pid namespace，隔离了宿主机上的进程可见性 B. 能，只是容器内外看到的进程 pid 不一样 正确答案： B 7. 运行 docker stop $container 命令停止一个容器后，容器的相关文件还在吗 A. 在，stop 只是停止了进程，文件等内容还是在宿主机上的 B. 不在，进程消失了，容器全部都不见了 正确答案： A 8. 已运行 docker run -d -t –name demo ubuntu top 和 docker run –name demo-x –pid container:demo ubuntu ps 命令，是否可以在 demo-x 容器内停止容器 正确 错误 正确答案： 正确 9. 已运行 docker run -d -t –name demo ubuntu top 命令, 是否在 demo 这个容器内部停止容器 正确 错误 正确答案： 错误 10. 已运行 docker run -d -t –name demo ubuntu top 和 docker run –name demo-x –pid container:demo ubuntu ps 命令，如果 demo 容器退出了，正在运行的 demo-x 容器是否会退出 正确 错误 正确答案：正确 ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:15","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"理解 etcd 的核心设计思想 6. etcd 集群中存在 3 个 server 时，重启其中一个 server 完全不会影响服务。 正确 错误 正确答案： 错误 9. 关于 etcd lease，以下说法正确的是 A. etcd 创建 lease 对象时，需要指定一个时间作为其超时时间。 B. lease 对象被创建后，超过设定的时间一定会被系统自动回收。 C. 将 key 关联到 lease 对象上，当 lease 对象超时后，key 会被系统自动回收。 D. etcd 支持将多个 key 关联到同一个 lease 对象上，从而大幅降低刷新 lease 的性能开销。 正确答案： A C D ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:16","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 17 讲：深入理解 etcd - etcd 性能优化实践 5. etcd 满足了 CAP 原理中的哪些特性 A. CA B. CP C. AP D. CAP 正确答案： B 8. 以下说法正确的是 A. 新的 etcd 采用了 segregated hashmap 算法管理 freelist B. freelist 是内部已存储数据页面的集合 C. 采用新的页面管理算法后，etcd 存储数据量大幅度提升 D. compact 删除历史数据不会影响 etcd 性能 正确答案： A C freelist 是内部存储被释放的数据页面的集合 10. 关于 etcd lease，以下说法正确的是 A. 新版本的 etcd 对 lease 处理进行了优化 B. etcd 中可以存有大量的 lease C. etcd 切换 leader 后，lease 会丢失 D. etcd 切换 leader 后，原有 lease ttl 信息会不准 正确答案： A D https://github.com/etcd-io/etcd/issues/9395 It is needed since only the leader records TTL for performance reasons. It wont be changed. We should document it though. But if you expect the leader changes much more frequent than lease can expire, you have to either make your cluster more reliable or shorter the lease. ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:17","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 18 讲：Kubernetes 调度和资源管理 1. 挑选一个合适节点作为抢占节点的策略当中，哪个因素是排在第一位的考虑因素 A. 破环 PDB 最少的节点 B. Pods 优先级加和最小的节点 C. Pods 数目最少的节点 D. 最近启动 Pod 的节点 正确答案: A 7. 在资源列表中 1.5Gi 内存也可以用以下哪个方式表达 A. 1500m B. 1500Mi C. 1536m D. 1536Mi 正确答案： D 10. 下列哪种 request/limit 使用方式代表创建 Burstable 的 Pod A. CPU/Memery 都填了，但 request\u003climit B. 只填了 CPU 资源的 request，Memory 资源 request 和 limit 都没填 C. CPU 和 Memory 资源都没填，但填了 GPU 的 request D. 只填了 CPU/Memory，且 request=limit 正确答案： A B C ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:18","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 19 讲：调度器的调度流程和算法介绍 1. 下列关于打分器（prioritize）的作用描述不正确的是 A. 能用来确保 Pod 之间的亲和部署 B. 用来尽量满足 Pod 和 Node 亲和部署 C. 支持 Pod 在节点上尽量打散 D. 可以用来支持 Pod 尽量调度到已有此镜像的节点 正确答案： A 4. 以下扩展点哪个是 scheduler extender 不支持的 A. filter B. prioritize C. bind D. prebind 正确答案： D 6. 调度节点选择的逻辑是 A. 随机选择节点用于过滤 B. 优先把一个 Zone 的节点过滤完之后，再选择下一个 Zone C. 选择节点按照 Zone 分组进行 RoundRobine 选择，使得取样模板在 zone 上更均衡 正确答案： C ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:19","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 20 讲：GPU 管理和 Device Plugin 工作机制 1.Device Plugin 的 AllocateResponse 中可以接收如下哪些参数 A. devices B. mounts C. envs D. cpus 正确答案： A B C(试卷说是单选, 题目有问题) 2.Device Plugin 中 API 可以用来反映设备健康状况的方法名称是 A. Allocate B. Register C. ListAndWatch D. PreStartContainer 正确答案： C 3.Kubernetes 是从哪个版本开始支持 Device Plugin A. 1.8 B. 1.9 C. 1.10 D. 1.11 正确答案： A https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.8.md#kubelet 4. 使用 Kubernetes 管理 GPU 资源可以利用 Kubernetes 的统一调度能力，使资源使用方能够用即申请，完即释放，从而盘活整个 GPU 资源池。 正确 错误 正确答案： 正确 5. 如果需要构建 GPU 容器镜像，必须要在镜像里安装英伟达驱动、CUDA 库。 正确 错误 正确答案： 错误, 驱动由宿主机提供, 通过挂载给容器使用 6. 必须要使用 Nvidia Docker 才能运行 GPU 容器。 正确 错误 正确答案： 错误 7. 可以通过 nvidia.com/gpu=0.5 申请 GPU。 正确 错误 正确答案： 错误 8.Device Plugin 机制只能支持 Nvidia GPU，而无法支持 AMD GPU。 正确 错误 正确答案： 错误 9. 当前 Kubernetes 先可以支持复杂场景的 GPU 调度，比如 GPU 精细调度，具体来说可以调度彼此间有 NVLink 连接的两个 GPU 卡。 正确 错误 正确答案： 错误 10.Kubernetes 通过哪些内部机制支持 GPU 管理 A. CNI Plugin B. Device Plugin C. Extended Plugin D. Cloud Provider 正确答案: B C ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:20","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 21 讲：Kubernetes 存储架构及插件使用 1. 下面哪个不是 CSI CRD 定义的对象 A. PVC B. CSIDriver C. CSINode D. VolumeAttachment 正确答案: A 2. 关于 Volume 的 Provision、Attach、Mount 操作，下面说法错误的是 A. PV controller 只能负责 Provision 操作 B. AD Controller 只能负责 Attach 操作 C. Volume Manager 只能负责 Mount 操作 正确答案: C 3. 关于存储卷回收策略，下面说法错误的是 A. Retain 模式：PVC 删除后，PV 依然存在 B. 动态生成的 PV，默认为 Retain 模式 C. Delete 模式：PVC 删除后，PV 同时被删除 D. Recycle 模式：PVC 删除后，PV 可再次使用 正确答案: B 4. 关于 Kubernetes VolumePlugin，下面说法错误的是 A. Volume Plugin 分为 In-Tree、Out-Of-Tree 两种类型 B. In-Tree 类型插件，和 Kubernetes 融合度高，是社区推荐的使用方式 C. Out-Of-Tree 类型插件，解耦了编排系统和存储服务，是社区推荐的使用方式 D. VolumePlugin 是 Kubernetes 对存储卷访问的接口抽象 正确答案: B 5. 关于 Flexvolume 接口，下面说法正确的是 A. Attach 接口一定会被调用 B. ExpandVolumeDevice 实现文件系统扩容 C. 所有接口都必须实现 D. MountDevice 接口实现设备挂载到 Global 目录 正确答案： D 6. 关于 Flexvolume、CSI，下面说法正确的有 A. 相比 Flexvolume，CSI 能提供更好的安全能力 B. Flexvolume 是非容器化部署，依赖难以解决 C. CSI、Flexvolume 都只能支持 Kubernetes 平台 D. CSI 通过容器化部署，是社区推荐的插件方案 正确答案： A B D 7. 关于 Flexvolume，下面说法正确的有 A. Flexvolume 可以支持 Attach 操作 B. Flexvolume 是一个守护进程 C. Flexvolume 可以支持 Provision 操作 D. Flexvolume 是运行在主机空间的程序 正确答案： A D 8. 关于 CSI 组件，下面说法正确的有 A. PV Controller 调用 External Provisioner 实现创建数据卷功能 B. 有些存储类型可以不部署 External Attacher C. Kubelet 直接调用 CSI Plugin 实现数据卷的 Mount/Unmount 操作 D. CSI Controller Server 和 CSI Node Server 每个节点都需要部署 正确答案： B C 9. 关于 pv、pvc 绑定，下面说法正确的有 A. 必须 Access Modes 相同的 pv、pvc 才可以绑定 B. PVC 定义的 Capacity 必须等于 PV 的 Capacity 才可以绑定 C. 可以通过 Selector 配置特定的 PVC、PV 绑定 D. PVC 找不到匹配的 PV 时，才会触发 Provisioner 创建 PV 正确答案： C D 10. 关于 CSI，下面说法正确的有 A. CSI 以容器方式部署 B. CSI-Provisioner 需要部署成 DaemonSet 模式 C. CSI Plugin 通过本地 Socket 与 kubelet 通信 D. CSI 只是针对 Kubernetes 设计的存储接口 正确答案： A C ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:21","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 22 讲：有状态应用编排：StatefulSet 1. 通过 StatefulSet 不能实现以下哪个功能 A. 应用扩缩容 B. 应用发布回滚 C. 应用重启 D. 应用副本数量维持 正确答案： C 2. 创建 StatefulSet spec 中的 template 字段，用处不包括 A. 声明 Pod 容器的挂载目录 B. 声明 Pod 需要的 pvc 模板 C. 指定镜像版本 D. 指定 Pod 容器重启策略 正确答案： B 3. 以下哪个是 StatefulSet 中要填写 serviceName 的根本原因 A. 有状态应用必须配置 service B. 通过 headless service 来为 StatefulSet 提供服务 C. 通过 headless service 来为 StatefulSet 的每个 Pod 提供唯一 hostname D. 通过 headless service 来提高有状态服务的性能 正确答案： C 4. 如果 StatefulSet 的 podManagementPolicy 设置为 Parallel，则下列哪个说法错误 A. 不再严格按照顺序 Ready 的方式串行创建 Pod B. 不再严格按照倒序串行缩容 Pod C. 不再严格按照倒序串行升级 Pod D. podManagementPolicy 是可选字段，yaml 中可以不填 正确答案： C 5. 以下关于 ControllerRevision 历史版本说法正确的是 A. 所有历史版本都会作为 ControllerRevision 保留 B. pod label 中的 controller-revision-hash 与对应版本 ControllerRevision name 一致 C. revisionHistoryLimit 字段不设置默认没有数量限制 D. 更新了 StatefulSet spec 中字段，就会创建一个新的 ControllerRevision 正确答案： B 6. 以下哪个不可能是名为 nginx-web 的 StatefulSet 扩容出来的 pod/pvc name A. nginx-web-1 B. nginx-web-15 C. tmp-nginx-web-3 D. nginx-web-tmp-1 正确答案： D 7. 通过配置 StatefulSet，可以使每个 Pod 对应一个独立的 PVC，也可以使所有 Pod 共用一个 PVC。 正确 错误 正确答案： 正确 8. 关于 StatefulSet 中的 volumeClaimTemplates，下列说法错误的有哪些 A. 创建出的 PVC name，就是 volumeClaimTemplates 中的 metadata.name 加一个 order 序号 B. 如果设置了 volumeClaimTemplates，那么每次创建 Pod 之前都会发生 PVC 创建 C. volumeClaimTemplates 里能设置多个 PVC 模板 D. 如果不设置 volumeClaimTemplates，那么 StatefulSet 创建出的 Pod 就无法使用 PVC 正确答案： A B D 9. 以下关于 StatefulSet 和 Deployment 的区别说法正确的有哪些 A. StatefulSet 的 Pod 能使用 PVC，Deployment 的 Pod 不能 B. StatefulSet 有的发布能力，Deployment 都有 C. StatefulSet 发布前后 Pod name 不变，而 Deployment 会变 D. StatefulSet 直接操作管理 Pod 资源，而 Deployment 则不会 正确答案： C D 10. 一个 replicas=10、partition=8 的 StatefulSet，在某一个时刻 status 可能处于以下哪些状态 A. currentReplicas:8 updatedReplicas: 2 B. currentReplicas:9 updatedReplicas: 1 C. currentReplicas:10 updatedReplicas: 10 D. currentReplicas:6 updatedReplicas: 2 正确答案： A B C D ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:22","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 23 讲：Kubernetes API 编程范式 1.Kubernetes CRD 是在哪个版本被引入的 A. 1.6 B. 1.7 C. 1.8 D. 1.9 正确答案： B 2. 自定义资源使用什么字段来嵌套其他子资源 A. status B. subresource C. spec D. metadata 正确答案： B 3. 自定义资源能够具备自己的状态字段吗 A. 能 B. 不能 正确答案： A 4.Kubernetes 自定义资源一般指的是 A. CRD B. 扩展 APIServer 5.CRD 必须配合 controller 才能有效果。 正确 错误 正确答案： 正确 6.Kubernetes 自定义资源出现的原因是什么 A. 用户自定义资源需求比较多 B. Kubernetes 原生资源无法满足需求 C. Kubernetes APIServer 扩展比较复杂 D. 用户对 Kubernetes 架构不满意 正确答案： A B C 7.Kubernetes CRD 可以和内置资源共享什么资源 A. kubectl B. RBAC C. Deployment D. Pod 正确答案： A B 8.Controller 通过（ ）来同时处理多个对象的请求 A. Queue B. Worker C. Handler D. Manager 正确答案： A B 9. 关于 Controller 的描述，以下正确的有 A. Controller 是 Kubernetes 的大脑 B. Controller 来完成具体的 CRD 操作 C. Controller 完成全部的 CRD 功能 D. Controller 必须配合 CRD 才能完成功能 正确答案： A B 10.Controller 一般具备哪几个函数来接受请求 A. AddFunc B. UpdateFunc C. DeleteFunc D. PopFunc 正确答案： A B C ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:23","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 24 讲：Kubernetes API 编程利器：Operator 和 Operator Framework 1. 在 webhook 业务逻辑中，下列哪些行为是不建议的 A. 设置缺省值 B. 校验字段正确性 C. 调用外部 api D. 处理非 CRD 对象 正确答案： C 2. 在 controller 入队逻辑中，下列哪些行为是不建议的 A. 查询 CRD 对象 B. 查询 CRD 关联对象 C. 根据对象字段做入队过滤 D. 处理业务逻辑 正确答案： D 3. 大多数情况下只能工作在主备模式的是 A. apiserver B. validating webhook C. mutating webhook D. controller 正确答案： D 4.controller 入队逻辑针对可能丢失事件的正确处理方法是什么 A. 无论什么事件都尽量入队 B. 给相关对象增加 finalizer C. 定时轮询资源对象 D. 同一个事件入队多次 正确答案： B 5.webhook 只能拦截处理 CRD 对象。 正确 错误 正确答案： 错误 ####　6.controller Reconcile 主循环返回错误会入队重试。 正确 错误 正确答案： 正确 7.operator 模式中，webhook 组件和 controller 组件都是必须的。 正确 错误 正确答案： 错误 8.controller 的入队逻辑只取决于 CRD 的状态变化。 正确 错误 正确答案： 错误 9. 下列哪些设计是不可取的 A. controller 主循环函数不幂等 B. controller 实时更新 CRD status 信息 C. 开发的多个 mutating webhook 有顺序依赖 D. validating webhook 依赖 mutating webhook 先执行 正确答案： A C 10. 下面哪种失败会导致 pod 创建失败 A. pod validating webhook 失败 B. pod mutating webhook 失败 C. pod controller 业务逻辑失败 D. pod controller 更新状态失败 正确答案： A B ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:24","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 25 讲：Kubernetes 网络模型进阶 1.Flannel-HostGW 方案精髓，是选以下哪个网卡上的 IP，做非本地节点网段的 GW A. CNI B. Node-NIC C. Remote-CNI0 D. Remote-Node-Nic 相关知识点： 对端网段选对端 node 网卡 IP 做 GW 正确答案： D 2. 不通过 Nodeport 接口，外部无法调用 Kubernetes 的 Service。 正确 错误 相关知识点： 还有其他办法，比如在某个节点插入外网卡，变成路由节点 正确答案： 错误 3. 容器里面必须有网络设备才能叫容器网络。 正确 错误 相关知识点： 还可以有用户态路径方案 正确答案： 错误 4. 常见的网络五元组元素包含 4 层协议类型号。 正确 错误 正确答案： 正确 5.Ingress 机制就是来替换 Service 的。 正确 错误 相关知识点： 不是，其实更好的辅助组件，更好对接 Service 正确答案： 错误 6.Pod 能且只能支持网络空间共享。 正确 错误 相关知识点： 还可以支持 ipc 等空间，可选 正确答案： 错误 7.Iptables 类型的 network policy 可以通杀一切带 Bridge 的容器网络数据方案。 正确 错误 相关知识点： Bridge 不使能 br-call-Iptables 功能，则不能起作用 正确答案： 错误 8.Underlay 方案全面优于 Overlay 方案，可以完全替代。 正确 错误 相关知识点： 不是，要看场景 正确答案： 错误 9. 有了 Service，云厂商的负载均衡服务不再有用武之地。 正确 错误 相关知识点： 不是，云厂商 LB 服务是 Servier 的最佳前端 正确答案： 错误 10.Docker 的桥接网络优势是什么 A. 天然集成在 Docker 引擎中 B. 与外部网络完全解耦 C. 能完美支持 Kubernetes 网络模型 D. Bridge 是内核最通用稳定的虚拟设备之一 正确答案： A B D ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:25","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 26 讲：理解 CNI 和 CNI 插件 1.Kubernetes 的网络插件接口是什么 A. CNI B. CSI C. CNM D. CRI 正确答案： A 2. 以下哪个不是路由模式的 CNI 插件 A. flannel-hostgw B. calico-bgp C. contiv D. flannel-alivpc 正确答案： C 3. 在虚拟化的环境中一般选择哪种类型的网络插件 A. Overlay B. Underlay C. 路由 正确答案： A 4.Kubernetes 通过 GRPC 接口调用网络插件。 正确 错误 正确答案： 错误 5.Overlay 模式实现的网络插件性能损失较大。 正确 错误 正确答案： 正确 6.Overlay 模式对底层网络环境要求小。 正确 错误 正确答案： 正确 7.CNI 插件一般由 Daemon 和 Binary 两部分组成。 正确 错误 正确答案： 正确 8.CNI 插件要负责的事情包括 A. 给 Pod 配置网卡和 IP 等网络配置 B. 配置 K8S Service 的负载均衡 C. 配置 Network Policy D. 打通 Pod 间网络的访问 正确答案： A C D 9. 以下哪个是 Underlay 网络模式的特点 A. 性能好 B. Pod 创建速度快 C. 对底层网络无要求 D. 可以和集群外资源互联互通 正确答案： A D 10. 下列哪些可以作为打通 Node 间网络通道的手段 A. Overlay 隧道 B. VPC 路由表 C. IP 按 Node 分段 D. BGP 路由 正确答案： A B D ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:26","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 27 讲：Kubernetes 安全之访问控制 1. 下列哪个选项不属于 Kubernetes API 请求流程 A. authentication B. authorization C. autoscaling D. admission control 正确答案： C 2. 在 x509 证书认证中，下列哪个字段会被 apiserver 作为用户模型中的用户 (user) A. Issuer –\u003e O B. Issuer -\u003e CN C. Subject -\u003e O D. Subject -\u003e CN 正确答案： D 3. 以下哪种说法是错误的 A. service account 是 Kubernetes 中唯一能够通过 API 方式管理的 apiserver 访问凭证 B. 对于已经创建的 pod，我们可以更新其已经挂载的 service account 内容 C. 用户可以通过 API 创建自定义名称的 service account D. 当一个 namespace 创建完成后，会同时在该 namespace 下生成名为 default 的一个 Service Account 和对应的 secret 实例 正确答案： B 4. 如果我们没有设置 KUBECONFIG 变量，kubectl 客户端还会尝试从下列哪个路径读取 kubeconfig 配置 A. $HOME/.kube/config B. $HOME/.config/kubeconfig C. $HOME/.config/userconfig D. $HOME/.kube/user 正确答案： A 5. 下列哪种认证方式是安全上不推荐的方式 A. Basic 认证 B. x509 证书认证 C. OpenID Connect 认证 D. Service Account 认证 正确答案： A 6. 下列哪个组件配置参数用于调整 Kubernetes 中 CertificateSigningRequest 实例签发证书的过期时间 A. kube-apiserver -\u003e tls-cert-file B. kube-apiserver -\u003e client-ca-file C. kube-controller-manager -\u003e experimental-cluster-signing-duration D. kubelet -\u003e rotate-certificates 正确答案： C 7.RBAC 中集群角色 ClusterRole 可以绑定到 namespace 中的一个具体的 object 实例。 正确 错误 正确答案： 错误 8. 在一个 RoleBinding 实例中，一个绑定只能指定唯一的 Role。 正确 错误 正确答案： 正确 9. 下列关于 RBAC 的说法，哪些是正确的 A. RBAC 策略模型中的 Subjects 可能包含开发人员，管理员，系统组件进程或是 pod 进程 B. RBAC 策略模型中的对象资源在 k8s 集群中指 Pod，Deployment 等各类 API 资源 C. RBAC 策略模型中的 Verbs 包括 list，watch，put 等 D. RBAC 策略模型中的角色可以对 k8s subresources（比如 nodes/status） 进行绑定 正确答案： A B D 10. 为了请求主体能够有权使用 kubectl exec –it pod-test bash，在主体绑定的角色模板中需要加入如下哪些策略 A. deployment： create B. pods： get C. service：create D. pod/exec：create 正确答案： B D ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:27","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 28 讲：容器运行时接口 CRI 1.Kubernetes 中，crictl 是什么 A. CRI 接口的性能测试工具 B. 操作 CRI 接口的命令行工具 C. CRI 接口的功能正确性测试工具 正确答案： B 2.Kubernetes 的容器运行时接口英文简写是什么 A. CNI B. CSI C. CRI 正确答案： C 3.Kubernetes 中，rkt 是什么 A. 是一种容器运行时 B. 是一种网络插件 C. 是一个调度器 正确答案： A 4.Kubelet 与 CRI 之间通过什么协议进行通信 A. gRPC B. HTTP/RESTful API C. UDP 正确答案： A 5.CRI-O 是哪个公司的开源产品 A. Google B. Red Hat C. Vmware D. AWS 正确答案： B 6. 在 CRI 的实现过程中，需要进行 CNI 操作。 正确 错误 相关知识点： 创建和删除 POD 的时候，需要调用 CNI 设置网络 正确答案： 正确 7.PauseContainer 是一个 CRI 接口。 正确 错误 相关知识点： Kubernetes 不支持 pause 语义 正确答案： 错误 8.gRPC 协议的优点是 A. 高性能 B. 有多种语言的实现 C. 可以自动生成接口代码 D. 支持双向流数据 正确答案： A B C D 9.CRI 有哪几类接口 A. Sandbox B. Container C. Image D. Storage 相关知识点： 存储不属于 CRI 的范畴 正确答案： A B C 10. 如何对 CRI 进行拓展 A. 直接修改 CRI 接口定义 B. 通过 annotation 传递自定义字段，在容器运行时的实现里识别 C. 修改 controller-manager 代码 正确答案： A B ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:28","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 29 讲：安全容器运行时 1.Kata Containers 从哪个版本开始支持 shim-v2 的 A. 1.2 B. 1.5 C. 1.6 D. 1.9 相关知识点： 这个幻灯片里没有，但讲课的时候提了，这个应该很难记住 正确答案： B 2.virtio-fs 应用了哪项技术可以跨沙箱共享只读内存 A. DDX B. DAX C. SGX D. DFX 相关知识点： DAX，为非易失内存开发的技术 正确答案： B 3.Kata Containers 项目是哪年宣布的 A. 2015 B. 2016 C. 2017 D. 2018 正确答案： C 4.gVisor 是用什么语言编写的 A. Go B. Rust C. Kotlin D. Scala 相关知识点： Go, Go 语言和 gVisor 都来自 G 开头的 Google 正确答案： A 5.gVisor 把什么操作交给 Gofer 进程来进行 A. Go 代码执行 B. 冷门系统调用 C. 内存管理 D. 文件操作 相关知识点： 最常见的是文件的 open 操作 正确答案： D 6. 在使用 Kata Containers 的时候，一个 Pod 里面可以有几个容器 A. 只能有一个 B. 可以有若干个 init container 和一个应用 container C. 可以有一个 container 和一个 sidecar D. 可以有多个 container 正确答案： D 7. 安全容器和 runC 都可以运行 OCI Image。 正确 错误 相关知识点： 是的，都支持 OCI 规范 正确答案： 正确 8. 最早的容器技术 Solaris Zone 在上个世纪的 1999 年就出现了。 正确 错误 相关知识点： 可能还在脑子里吧，1999 年出现的是 FreeBSD Jail 正确答案： 错误 9.Kata Containers 目前可以支持下列哪些虚拟机监视器（VMM） A. VMWare B. Qemu C. Xen D. Hyper-V E. Firecracker 正确答案： B E 10. 下列哪种机制被 gVisor 用来拦截容器的 syscall A. ptrace B. KVM C. dtrace D. strace E. JVM 相关知识点： 其他几个都是过来陪跑的，但是这个需要拓展学习以下 正确答案： A B ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:29","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["云原生"],"content":"第 30 讲：理解 RuntimeClass 与使用多容器运行时 1. 以下哪段配置表示 containerd 的默认容器运行时 A. plugins.cri.containerd.runtimes.runc B. plugins.cri.containerd.runtimes.runv C. plugins.cri.containerd.default_runtime 正确答案： C 2.Kubernetes 哪个版本引入了 RuntimeClass A. 1.10 B. 1.12 C. 1.14 D. 1.16 正确答案： B 3. 删除 RuntimeClass 后，对已有的 Pod Overhead 有影响吗 A. 无 B. 有 C. 需要根据上下文判断 正确答案： A 4. 如果使用 RuntimeClass 的 Overhead，需要开启哪个 admisson A. ResourceQUota admission B. RuntimeClass admisson C. PodOverhead admission 正确答案： B 5.Pod Overhead 支持手动配置或更改。 正确 错误 正确答案： 错误 6.RuntimeClass 是 cluster 级别的资源。 正确 错误 正确答案： 正确 7. 在没有配置 node label 的情况下，只要 Pod 引用的 RuntimeClass 配置了 Scheduling，Pod 就一定会被调度到有对应容器运行时的节点上。 正确 错误 正确答案： 错误 8. 哪些容器运行时是基于 CRI 实现的 A. gVisor B. rkt C. kata D. docker 正确答案： A C 9.Pod Overhead 会影响哪些功能 A. HPA B. Pod 调度 C. ResourceQuota D. Kubelet Pod 驱逐 正确答案： B C D 10. 以下哪些是 Kubernetes v1.16 版本新增特性 A. Pod Overhead B. Handler C. Scheduling 正确答案： A C ","date":"2019-11-14","objectID":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/:0:30","tags":["CNCF","CKA"],"title":"CNCF × Alibaba 云原生技术公开课测试答案","uri":"/cncf-alibaba-%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8A%80%E6%9C%AF%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B5%8B%E8%AF%95%E7%AD%94%E6%A1%88/"},{"categories":["Python"],"content":"现象 在查看数据时发现部分数据库时间字段存在精度丢失的问题 ","date":"2019-10-15","objectID":"/peeweext-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E6%88%B3%E7%B2%BE%E5%BA%A6%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/:1:0","tags":["ORM"],"title":"Peeweext 日期时间戳精度丢失问题","uri":"/peeweext-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E6%88%B3%E7%B2%BE%E5%BA%A6%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/"},{"categories":["Python"],"content":"技术原理 Peeweext 提供了高精度的 DATETIME 类型支持, 但是其实现是通过对MySQLDatabase, PostgresqlDatabase 字段类型映射打补丁实现的 # peeweext.fields.py pw.MySQLDatabase.field_types.update({'DATETIME': 'DATETIME(6)'}) pw.PostgresqlDatabase.field_types.update({'DATETIME': 'TIMESTAMPTZ'}) class DatetimeTZField(pw.Field): field_type = 'DATETIME' 但问题在于, 虽然 field_types 是类属性, 但是Database 在实例化时会复制一份而不是直接使用, 这就导致一旦 Database 在打补丁之前实例化, 后续 DATETIME 类型就丢失精度了 # peewee.Database class Database(_callable_context_manager): context_class = Context field_types = {} operations = {} ... def __init__(self, database, thread_safe=True, autorollback=False, field_types=None, operations=None, autocommit=None, autoconnect=True, **kwargs): # 此处的 merge_dict 会复制一份 self._field_types = merge_dict(FIELD, self.field_types) self._operations = merge_dict(OP, self.operations) if field_types: self._field_types.update(field_types) if operations: self._operations.update(operations) 而通过查看 Peeweext 初始化逻辑发现导入顺序确实是有问题的 # peeweext.sea/flask.Peeweext class Peeweext: def __init__(self, ns='PW_'): self.ns = ns def init_app(self, app): config = app.config.get_namespace(self.ns) conn_params = config.get('conn_params', {}) self.database = db_url.connect(config['db_url'], **conn_params) self.model_class = import_string( config.get('model', 'peeweext.model.Model')) self._try_setup_celery() 注意这里 database 是在 model_class 导入前实例化的, peeweext.model 导入了 peeweext.fields 才会会触发打补丁 因此数据库中可能会存在时间字段精度丢失问题 需要注意的是, 如果 extension 被初始化了两次再被使用就不会有问题了, 因为第一次初始化时会触发打补丁, 第二次初始化 database 中的 _field_types 就是正确的了. 调用 create_app 多次或者多个 extension 指向同一个实例(pwdb = pwshard = Peeweext(ns=\"PWSHARD_\"))都会使其多次初始化 当然这并不是正确的做法, 只是给出部分字段精度是正确的原因 ","date":"2019-10-15","objectID":"/peeweext-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E6%88%B3%E7%B2%BE%E5%BA%A6%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/:2:0","tags":["ORM"],"title":"Peeweext 日期时间戳精度丢失问题","uri":"/peeweext-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E6%88%B3%E7%B2%BE%E5%BA%A6%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/"},{"categories":["Python"],"content":"解决方案 业务方检查数据库相关字段是否是正确的, 以及评估精度丢失对业务的影响 框架进行更新修补相关问题 业务方使用新版的框架 ","date":"2019-10-15","objectID":"/peeweext-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E6%88%B3%E7%B2%BE%E5%BA%A6%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/:3:0","tags":["ORM"],"title":"Peeweext 日期时间戳精度丢失问题","uri":"/peeweext-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E6%88%B3%E7%B2%BE%E5%BA%A6%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/"},{"categories":["Python"],"content":"Peeweext 修复方案 方案 1: 仍然打补丁 初始化 Peeweext.database 逻辑移至导入 model_class 之后, 即: class Peeweext: def init_app(self, app): ... self.model_class = import_string( config.get('model', 'peeweext.model.Model')) self.database = db_url.connect(config['db_url'], **conn_params) .... 虽然仍然能够打补丁成功, 但实际上允许自定义 Model 的功能没有什么意义了, 因为一旦使用自定义的 Model, 补丁又要失效了 打补丁本身不是一个好的模式 这个修复方案最简单, 代价最小 方案 2: 取消打补丁 取消打补丁, 将 DatetimeTZField 改为高精度类型, 重载 ddl_datatype 使其能适配在不同数据库下的表现, 所有需要高精度时间的字段使用此字段 实际上 peewee 自带了一个高精度时间戳的字段实现 TimestampField, 使用这个字段也未尝不可 ","date":"2019-10-15","objectID":"/peeweext-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E6%88%B3%E7%B2%BE%E5%BA%A6%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/:3:1","tags":["ORM"],"title":"Peeweext 日期时间戳精度丢失问题","uri":"/peeweext-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E6%88%B3%E7%B2%BE%E5%BA%A6%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98/"},{"categories":[],"content":"推荐日本惊悚电影《告白》（2010），该片讲述的是高中老师森口悠子的女儿在学校游泳池溺水身亡，警方鉴定这是意外事故，而经过森口悠子的调查，断定高中一年级B组的少年A和少年B是杀害自己女儿的凶手，为了报复，森口悠子在班级所有学生面前指认了凶手，并且用了自己的方式展开报复。森口悠子埋下了报仇的种子就离开了学校，任由种子生根发芽。 电影赏析： 叙事方式：该片和一般的惊悚电影表现形式不太一样，采取了分段的第一人称叙事的形式，全片一共分为了6段，不同人物从不同的视角出发，看待事件的发展。电影中的节奏情绪从一开始的平淡到最后的高亢，即使分成不同人物叙述，也没有丝毫的违和感。同时，每位告白者都拥有各自的秘密，这种秘密都成为电影后期叙事的转折和基石。 电影配乐和镜头：电影中的配乐乍一听和电影的主旋律十分不符，尤其是一些较为轻快的配乐。但结合电影来看，并没有违和感，轻快俏皮的音乐配合大量慢镜头，反衬了人物的心理变化。《告白》营造了冰冷的氛围。色调上灰色、黑色占据了很大篇幅，人物经常出现在黑暗或者封闭的空间里。与之相对应的是一些空镜头，花朵、水滴还有天空。它们看上去很美，却让人很难进入欣赏美的心境。 电影主题：电影浅则讨论了未成年人犯罪问题，深则讨论了人性本恶的观点。日本校园未成年学生欺凌越发严重，这种欺凌很有可能会印象孩子一生，但这些欺凌者却不用收到任何法律的严苛制裁，本片也在谴责未成年人保护法，让森口悠子用更加“公正”的方式去制裁犯罪者。同时人性本恶还是人性本善，一直都是争论的焦点，而随着时代的发展，越来越多的人认为人性本恶，人类个体在胚胎之时就会采用下意识的自私残忍手段从母亲手里抢来生存的机会，本片没有一个真正的“无罪之人”，无论是犯罪的少年A和少年B，还是欺凌少年A和少年B的同学，所有人都发挥着他们本身的恶。 电影：https://tv.sohu.com/v/dXMvMjA2MzIyNDYvMTU1NDM3MTYuc2h0bWw=.html ","date":"2019-08-18","objectID":"/%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%E5%91%8A%E7%99%BD/:0:0","tags":["电影"],"title":"电影推荐《告白》","uri":"/%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%E5%91%8A%E7%99%BD/"},{"categories":["devops"],"content":"问题背景 公司核心项目接入并且流量切换至新版后对 ES 集群性能产生了较大影响 同时有几个项目流量较大, 均未接入 APM, 但是需要接入 瓶颈在 ES 集群而不是 APM Server, agent 到 apm-server, apm-server 到 ES 集群都是批量操作 偶尔会出现 APM 写入不够导致触发大量报错, 然后 raw 写入更多的恶性循环 ","date":"2019-08-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:1:0","tags":["APM"],"title":"记一次 Elastic APM 性能调优","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["devops"],"content":"ES APM 基本原理 一个 transaction 会创建多个 ES document, 其中有两类: transaction: 一个 transaction 对应一条, 记录该 transaction 的元信息和总体的请求时间 span: 一个 transaction 对应多条, 该 transaction 具体包括哪些调用, 数量取决于子调用的数量和配置的 TRANSACTION_MAX_SPANS (默认 500) ","date":"2019-08-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:2:0","tags":["APM"],"title":"记一次 Elastic APM 性能调优","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["devops"],"content":"OpenTracing 关于 tracing 的基本原理可以去看一下 OpenTracing 语义标准 , Elastic APM 也提供了对该语义标准的 支持 ","date":"2019-08-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:2:1","tags":["APM"],"title":"记一次 Elastic APM 性能调优","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["devops"],"content":"调优 ","date":"2019-08-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:3:0","tags":["APM"],"title":"记一次 Elastic APM 性能调优","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["devops"],"content":"采样率 TRANSACTION_SAMPLE_RATE 采样率指的是 transaction 有多大的概率被 完整地 发送至 APM Server 设 每秒请求量 $QPS$ ES 每秒写入量 $EsQPS$ $$ EsQPS = SampledEsQPS + UnsampledEsQPS $$ 其中 $$ \\begin{aligned} SampledEsQPS \u0026= QPS * SampleRate * (AvgSpanNum + 1) \\\\ UnsampledEsQPS \u0026= QPS * (1- SampleRate) * 1 \\\\ EsQPS \u0026= QPS * (SampleRate * (AvgSpanNum + 1) + (1- SampleRate)) \\\\ \u0026= QPS * (SampleRate * AvgSpanNum + 1) \\\\ SampleRate \u0026= \\frac{EsQPS \\div QPS - 1}{AvgSpanNum} \\\\ AvgSpanNum \u0026= \\frac{EsQPS \\div QPS - 1}{SampleRate} \\end{aligned} $$ 假设一个请求对应一个 transaction $$ ApmDelay = \\frac{1 \\div SampleRate}{QPS} $$ $ApmDelay$ 表示 $QPS$ 在 $x$ 时大约 $QPS * SampleRate$ 秒能观测到 span 数据 此时我们便可以根据 $ApmDelay$ 和 $QPS$ 设定合适的采样率 ","date":"2019-08-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:3:1","tags":["APM"],"title":"记一次 Elastic APM 性能调优","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["devops"],"content":"APM Server We still record overall time and the result for unsampled transactions, but no context information, labels, or spans. 根据官方文档的说明, 即使未被采样仍然会产生一些统计数据, 从我们的实际使用场景来说, 每秒 transaction 数量, 平均请求时间等信息通过服务网关能做到实时监控, APM 这些数据不准确是可以接受的, 通过过滤这些数据, 能够减轻 Elastic Search 集群的写入压力和磁盘压力 通过配置, 不将未采样的 transaction 发往 ES 集群 processors:- drop_event:when:equals:transaction.sampled:false 可以看到, 配置后 APM Server 不再写入未被采样的 transaction 数据 观察调整后 ES 数据写入速率的变化 其中写入量没有变化的服务采样率为 1 绿线代表的服务采样率为 $10^{-6}$ 对于采样率不够低的服务, 不存储未采样的 transaction 的服务写入量没有明显变化 ","date":"2019-08-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:4:0","tags":["APM"],"title":"记一次 Elastic APM 性能调优","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["devops"],"content":"效果如何 这里简单根据公式: $$ \\begin{aligned} TPS \u0026= UnampledTrans + SampledTrans * (1 + AvgSpans) \\\\ EsQPS \u0026= TPS * (1- SampleRate) + TPS * SampleRate * (1 + AvgSpans) \\end{aligned} $$ 可以得到一张关于图, 可以看到, 在采样率低于 0.1 的时候, 优化效果是比较明显的, 不过 transaction 的平均 span 数量 (AvgSpans) 越大, 得到的效果越差 ","date":"2019-08-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:4:1","tags":["APM"],"title":"记一次 Elastic APM 性能调优","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["devops"],"content":"附录 APM Python Agent Reference » Configuration Agent tuning and overhead Tune APM Server ","date":"2019-08-01","objectID":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/:5:0","tags":["APM"],"title":"记一次 Elastic APM 性能调优","uri":"/%E8%AE%B0%E4%B8%80%E6%AC%A1-elastic-apm-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"categories":["Snippet"],"content":"MySQL工具脚本.sql MySQL工具脚本.sql -- 按客户端 IP 分组，看哪个客户端的链接数最多 select client_ip,count(client_ip) as client_num from (select substring_index(host,':' ,1) as client_ip from processlist ) as connect_info group by client_ip order by client_num desc; -- 查看正在执行的线程，并按 Time 倒排序，看看有没有执行时间特别长的线程 select * from information_schema.processlist where Command != 'Sleep' order by Time desc; -- 找出所有执行时间超过 5 分钟的线程，拼凑出 kill 语句，方便后面查杀 select concat('kill ', id, ';') from information_schema.processlist where Command != 'Sleep' and Time \u003e 300 order by Time desc; -- 确定一个排序语句是否使用了临时文件 /* 打开 optimizer_trace，只对本线程有效 */ SET optimizer_trace='enabled=on'; /* @a 保存 Innodb_rows_read 的初始值 */ select VARIABLE_VALUE into @a from performance_schema.session_status where variable_name = 'Innodb_rows_read'; /* 执行语句 */ select city, name,age from t where city='杭州' order by name limit 1000; /* 查看 OPTIMIZER_TRACE 输出 */ SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G /* @b 保存 Innodb_rows_read 的当前值 */ select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read'; /* 计算 Innodb_rows_read 差值 */ select @b-@a; /* 这里需要注意的是，为了避免对结论造成干扰，我把 internal_tmp_disk_storage_engine 设置成 MyISAM。否则，select @b-@a 的结果会显示为 4001。这是因为查询 OPTIMIZER_TRACE 这个表时，需要用到临时表，而 internal_tmp_disk_storage_engine 的默认值是 InnoDB。如果使用的是 InnoDB 引擎的话，把数据从临时表取出来的时候，会让 Innodb_rows_read 的值加 1。 */ ","date":"2019-03-30","objectID":"/snippet/mysql%E5%B7%A5%E5%85%B7%E8%84%9A%E6%9C%AC/:1:0","tags":[],"title":"MySQL工具脚本","uri":"/snippet/mysql%E5%B7%A5%E5%85%B7%E8%84%9A%E6%9C%AC/"},{"categories":["阅读"],"content":"序 这篇分享不讲具体特性，不讲分布式实现，从使用场景和底层存储出发，了解核心概念，重在理解各类型数据库的本质和其设计带来的优缺点，为了帮助大家理解，本文部分知识超出了书本内容，顺序也做了相应调整。 ","date":"2018-09-27","objectID":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/:0:0","tags":["数据库"],"title":"数据库选择和实现的微妙平衡 - 《七周七数据库》读书笔记","uri":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"categories":["阅读"],"content":"关于《七周七数据库》 不建议花大量时间去完成新手实践的内容，实际需要时再去了解也不迟，重在扩充知识面。 最有价值的是附录和每一章的总结，这两个部分看懂了，整本书就差不多了。 翻译一般。 从场景出发 - OLTP vs. OLAP 数据处理大致可以分成两大类： 联机事务处理OLTP（On-Line Transaction Processing） 联机分析处理OLAP（On-Line Analytical Processing）。 OLTP是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。 OLAP是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。 OLTP 系统强调数据库内存效率，强调内存各种指标的命令率，强调绑定变量，强调并发操作； OLAP 系统则强调数据分析，强调SQL执行市场，强调磁盘I/O，强调分区等。 从存储出发 - 数据规模与数据复杂度之间的关系 上图是下面介绍的几种 NoSQL 数据库数据规模与数据复杂度之间的关系，我们可以看到，一种数据库实现时，要想承载更大的数据规模，其数据复杂度必须要随之下降，因为关系简单的数据更易进行分片和复制。 接下来简单介绍传统关系型数据库，然后按照横轴方向介绍几种类型的数据库。 几种常见数据库类型 ","date":"2018-09-27","objectID":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/:1:0","tags":["数据库"],"title":"数据库选择和实现的微妙平衡 - 《七周七数据库》读书笔记","uri":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"categories":["阅读"],"content":"关系型(Relational DBMS) 关系数据库，是创建在关系模型基础上的数据库，借助于集合代数等数学概念和方法来处理数据库中的数据。 表（关系Relation）是以行（属性Attribute）和列（值组Tuple）的形式组织起来的数据的集合。一个数据库包括一个或多个表（关系Relation）。例如，可能有一个有关作者信息的名为authors的表（关系Relation）。每列（值组Tuple）都包含特定类型的信息，如作者的姓氏。每行（属性Attribute）都包含有关特定作者的所有信息：姓、名、住址等等。在关系型数据库当中一个表（关系Relation）就是一个关系，一个关系数据库可以包含多个表（关系Relation） 关系型数据库的优势在于严格的约束，强一致性和支持灵活的查询，缺点是对水平扩容支持比较差，目前主要高可用方案是通过主从复制实现，数据的水平扩展可以通过分区，分库，分表等策略实现，但是无论是哪种方式，都会有以下问题。 事务问题 在执行分库分表之后，由于数据存储到了不同的库上，数据库事务管理出现了困难。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价；如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。 跨库跨表的join问题 在执行了分库分表之后，难以避免会将原本逻辑关联性很强的数据划分到不同的表、不同的库上，这时，表的关联操作将受到限制，我们无法join位于不同分库的表，也无法join分表粒度不同的表，结果原本一次查询能够完成的业务，可能需要多次查询才能完成。 额外的数据管理负担和数据运算压力 额外的数据管理负担，最显而易见的就是数据的定位问题和数据的增删改查的重复执行问题，这些都可以通过应用程序解决，但必然引起额外的逻辑运算，例如，对于一个记录用户成绩的用户数据表userTable，业务要求查出成绩最好的100位，在进行分表之前，只需一个order by语句就可以搞定，但是在进行分表之后，将需要n个order by语句，分别查出每一个分表的前100名用户数据，然后再对这些数据进行合并计算，才能得出结果。 ","date":"2018-09-27","objectID":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/:2:0","tags":["数据库"],"title":"数据库选择和实现的微妙平衡 - 《七周七数据库》读书笔记","uri":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"categories":["阅读"],"content":"键-值型(Key-value Stores) 顾名思义，KV存储库将键与值配对，类似于所有流行编程语言中的映射（或哈希表）。某些KV实现允许复杂的值类型，如哈希或列表，但这不是必需的。 键-值型存储可能是数据库管理中最简单的形式，一般来说单纯的键值数据库是不能满足复杂应用的需求的，但是另一方面，其简单的特性让它在特定场景下的表现非常出色。 Riak 是一个分布式的键值数据库，支持 MapReduce 和水平扩容，Riak 允许通过改变三个值：N、W与R，来控制集群的读写。N是一次写入最终复制到的节点数量，换句话说，就是集群中的副本数量。W是一次成功地写入响应之前，必须成功写入的节点数量。如果W小于N，就认为某次写入是成功的，即使Riak依然在复制数据。最后，R是成功读出一项数据所必需的节点数量。如果R比可用的复制数量大，读出请求将会失败。其原理是一致哈希算法，具体逻辑可以阅读编程之法：算法和面试心得 - 一致性哈希算法。 而 Redis，从基本层面上说，它是一个键-值对存储库。但这种简单的说法并不全面。虽然 Redis 没有达到文档型数据库的程度，但它支持高级的数据结构。它支持基于集合的查询操作，但不支持关系数据库中同样的粒度或类型。当然，它很快，为了速度而在持久性方面作出了让步。 Redis 把自己定义为高级数据结构服务器，此外，它也是阻塞队列（或栈）和发布-订阅系统。它支持可配置的到期策略、持久性级别，以及复制选项。所有这些使得 Redis 不仅是某类数据库中的一员，更是有用的数据结构算法和程序的工具包。 ","date":"2018-09-27","objectID":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/:3:0","tags":["数据库"],"title":"数据库选择和实现的微妙平衡 - 《七周七数据库》读书笔记","uri":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"categories":["阅读"],"content":"宽列型(Wide Column Stores) 列型（或面向列的数据库）的命名源自于其设计的一个重要方面，即来自一个给定的列（在二维表的意义上）的数据存放在一起。相比之下，面向行的数据库（如RDBMS），将一行的信息保存在一起。这种差异看起来似乎无关紧要，但实际上这种设计决策的影响很深。在面向列的数据库中，添加列是相当简易的，而且是逐行完成的。每一行可以有一组不同的列，或完全没有，允许表保持稀疏（sparse），而不会产生空值的存储成本。在结构方面，列型数据库大约介于关系数据库和键-值存储库之间。 你可以把宽列型数据库可以看做是二维的键-值型数据库，就能理解其特性了。 在宽列型数据库中，竞争相比关系数据库或键-值存储较少。我们以 HBase 为例介绍下宽列型数据库的核心概念。 在HBase表中，键可以是任意字符串，每个键都映射到一行数据。行本身也是一个映射表，其中的键称为列，而值就是未解释的字节数组。列按照列族（column family）进行分组，所以列的完全名称包含两个部分：列族名称和列限定符（column qualifier）。通常它们用一个冒号连接起来（例如，‘family:qualifier’）。 ![HBase的表包含行、键、列族、列和值](img/图4-1 HBase的表包含行、键、列族、列和值.jpg) 在这张图中，有一张假想的表，它有两个列族：color和shape。该表有两行（虚线框表示），由行键来唯一标识：first和second。请看第一行，我们看到它在列族color中有3列（限定符分别是red、blue和yellow），在列族shape中有1列（square）。行键和列名（包括列族和限定符）的组合，形成了定位数据的地址。在这个例子中，三元组first/color:red指向了值’#F00’。 ","date":"2018-09-27","objectID":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/:4:0","tags":["数据库"],"title":"数据库选择和实现的微妙平衡 - 《七周七数据库》读书笔记","uri":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"categories":["阅读"],"content":"文档型(Document stores) 我们可以将文档型数据库理解为，值类型为文档的键值数据库，因为其核心的存储引擎实际上就是键值存储，每个文档的键是文档的位置信息，值为存储的文档。位置信息的核心就是每个文档的独一无二的标识符（但并不代表标识符就是文档的位置信息）。 也正因为值为文档，文档型数据库在数据结构上表现出了高度的灵活性，允许有可变域。该系统对输入的数据很少有限制，只要它满足基本要求，可以表示为一个文档。在建索引、自由定义的查询、复制、一致性及其他设计决策等方面，不同的文档数据库采取了不同的方法。 ","date":"2018-09-27","objectID":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/:5:0","tags":["数据库"],"title":"数据库选择和实现的微妙平衡 - 《七周七数据库》读书笔记","uri":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"categories":["阅读"],"content":"MongoDB MongoDB 是目前最为流行的 NoSQL 数据库，它是一种面向集合，模式无关的文档型数据库。其中数据以“集合(Collection)”的方式进行分组，每个集合都有单独的名称并可以包含无限数量的文档。这里的集合同关系型数据库中的表（table）类似，唯一的区别就是它并没有任何明确的结构，文档（Document）是集合中数据的最小单元，概念可以与关系型数据库中的行（row）对应。 虽然我们与 MongoDB 交互式时的数据是 JSON 格式的，但实际上 MongoDB 数据库中的数据存储和网络传输格式是 BSON，它是一种二进制表示形式，能用来表示简单数据结构、关联数组（MongoDB中称为“对象”或“文档”）以及MongoDB中的各种数据类型。BSON之名缘于JSON，含义为Binary JSON（二进制JSON）。 与JSON相比，BSON 着眼于提高存储和扫描效率。BSON 文档中的大型元素以长度字段为前缀以便于扫描。在某些情况下，由于长度前缀和显式数组索引的存在，BSON使用的空间会多于JSON。 ","date":"2018-09-27","objectID":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/:6:0","tags":["数据库"],"title":"数据库选择和实现的微妙平衡 - 《七周七数据库》读书笔记","uri":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"categories":["阅读"],"content":"图型(Graph DBMS) 这是一种不太常用的数据库类型，图数据库善于处理高度互联的数据。图数据库包含节点及节点之间的关系。节点和关系可以有一些属性（一些键-值对），用来存储数据。图数据库的真正实力是按照关系遍历节点。 图型数据库通常不能提供所有节点的索引，根据属性值直接访问节点是无法实现的，必须要通过遍历。 图型数据库的代表是 Neo4j，Neo4j 被称为 property graph，除了顶点（Node）和边(Relationship，其包含一个类型)，还有一种重要的部分——属性。无论是顶点还是边，都可以有任意多的属性。属性的存放类似于一个哈希表，键为一个字符串，而值必须是 Java基本类型、或者是基本类型数组，比如说String、int或者int[]都是合法的。 在这个例子中，A~E表示 Node 的编号，R1~R7 表示 Relationship 编号，P1~P10 表示Property 的编号。 Node 的存储示例图如下,每个 Node 保存了第1个 Property 和 第1个 Relationship： Relationship 的存储示意图如下： 从示意图可以看出，从 Node-B 开始，可以通过关系的 next 指针，遍历Node-B 的所有关系，然后可以到达与其有关系的第1层Nodes,在通过遍历第1层Nodes的关系，可以达到第2层Nodes,… 从 CAP 定理出发 CAP理论主张任何基于网络的数据共享系统，都最多只能拥有以下三条中的两条： 数据一致性（C），等同于所有节点访问同一份最新的数据副本； 对数据更新具备高可用性（A）； 能容忍网络分区（P）。 附录：数据库对比表格 来自《七周七数据库》，相关数据可能随时间发生变化 附录：推荐阅读 CAP理论十二年回顾：“规则\"变了 分布式数据库TiDB整体概述 参考链接 《七周七数据库》 https://db-engines.com/en/system/InfluxDB https://db-engines.com/en/article/Time+Series+DBMS http://qinxuye.me/article/introduction-to-neo4j/ https://db-engines.com/en/article/Graph+DBMS OLTP和OLAP浅析 https://db-engines.com/en/article/Wide+Column+Stores https://db-engines.com/en/article/Relational+DBMS Neo4j 底层存储结构分析 Sharding：分表、分库、分片和分区 Key-value Stores HBase Cassandra BSON MongoDB · 引擎特性 · MongoDB索引原理 OLTP-vs-OLAP 聊聊MySQL、HBase、ES的特点和区别 MySQL · 引擎特性 · InnoDB 文件系统之文件物理结构 ","date":"2018-09-27","objectID":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/:7:0","tags":["数据库"],"title":"数据库选择和实现的微妙平衡 - 《七周七数据库》读书笔记","uri":"/%E4%B8%83%E5%91%A8%E4%B8%83%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"categories":["阅读"],"content":"发现这本书，是因为这几天在寻找有关时间管理的理论和方法，然后发现了柳比歇夫时间记录法，便开始了阅读这本书。而实际开始阅读这本书时才发现，这并不是系统的方法论，而是一本以柳比歇夫为主人公的纪实散文。 和书中说的一样，书中起初的一小部分是枯燥无味的，这是为柳比歇夫这个主人公而做铺垫，到了后来，便为这个“古怪”而又坚毅的主人公所吸引，为作者和译者高超的文笔所折服。读着读着，越来越感同身受，原来柳比歇夫也并不是神人，他也会分心，也会纠结，会伤心，会为生活而奔波。好在，他这一生是幸福的，虽有未完成的工作，也不会陷入无谓的遗憾和自责当中。 书的最后，以《与时间统计法无关-谈奇特的一生的创作》为题，附上了格拉宁当时的书评，所谓时间统计法，更重要的是人的态度和持之以恒的品质。“一个人只有向自己提出远大目标时，这个时间统计法才成立”，时间统计法不是捷径，它只是一个工具，后面的路还很长，还需要你一步步地走下去！ 附1 - 简明时间统计法要点 树立一个远大的目标 持之以恒 尽量记录每天所有的活动时间花费，养成对时间的感知能力 时间开销日记格式: 日期+事件+花费时间，每天记录5～7行 每个月做月度总结，年底做年度总结，以总结为镜，检查自己的工作效率 把时间当成金钱，从收入和支出两条渠道进行统计，最后计算出自己向目标前进了多少 设定几条守则，例如每天至少睡眠8小时，累了立即去休息等，确保每天的状态稳定 放弃一些无意义的时间消耗，例如不必要的应酬等，节约自己的时间 不断更新自己的方法使之更加合适和高效 附2 - 微信读书中这本书的排版 封面噱头太大，一股洗脑成功学的感觉，一部分迫切找到时间管理灵药的人怕是要失望了 书的排版很好，一些内容做了加重处理帮你圈出重点，章节后有简短的要点提示 ","date":"2017-07-24","objectID":"/%E5%A5%87%E7%89%B9%E7%9A%84%E4%B8%80%E7%94%9F%E4%B9%A6%E8%AF%84/:0:0","tags":["微信读书"],"title":"《奇特的一生》书评","uri":"/%E5%A5%87%E7%89%B9%E7%9A%84%E4%B8%80%E7%94%9F%E4%B9%A6%E8%AF%84/"},{"categories":["Go"],"content":"背景 最近在用Go语言做舆情监测相关的毕设，在做数据抓取模块时需要一个HTTP请求和响应存储的中间件，需要对请求和响应进行存储和去重，用到了请求指纹的计算。 ","date":"2017-03-29","objectID":"/http%E8%AF%B7%E6%B1%82%E6%8C%87%E7%BA%B9%E7%9A%84%E8%AE%A1%E7%AE%97/:1:0","tags":["HTTP","哈希"],"title":"HTTP请求指纹的计算","uri":"/http%E8%AF%B7%E6%B1%82%E6%8C%87%E7%BA%B9%E7%9A%84%E8%AE%A1%E7%AE%97/"},{"categories":["Go"],"content":"请求指纹算法 什么是请求指纹呢？请求指纹指的是一个能唯一确定一个HTTP请求的哈希值，对于哈希值的计算我们有很多现成的算法，这里我们所需要关注的问题是如何确定一个请求的唯一性。 我们知道，一个HTTP请求，主要包括了请求方式，请求链接，请求头部和请求体几个部分组成，首先可以确定的是，当请求方式不同时请求肯定是不相同的，而对于请求链接，请求参数和请求体三个部分情况则需要具体讨论。 首先对于请求链接，RFC定义的链接基本形式如下: scheme://[userinfo@]host/path[?query][#fragment] scheme，userinfo，host，path，query是服务器决定其响应的部分，fragment是本地浏览器的标记，因此这一部分对我们的请求是不产生任何影响的，计算指纹时需将其去除。 对于query查询字段，我们知道，查询参数的顺序是不会影响请求的结果的，而且如果没有参数时是否带上?也不影响，也就是说http://www.example.com/query?和http://www.example.com/query这两个链接是相同的，http://www.example.com/query?id=111\u0026cat=222和http://www.example.com/query?cat=222\u0026id=111也是相同的。在计算请求指纹时我们需要先将请求的地址标准化（去掉fragment部分，强制添加?，对查询参数进行排序）。 接着是请求头部，一般来说，我们在发送请求时的头部是固定的，请求头部可能影响我们的响应也有可能不影响，而且服务器也会影响到我们的头部，如设置Cookie，因此这一部分的计算是否包含在内要视情况而定，因此在计算时作为可选部分。当计算头部时，由于头部的顺序是无关紧要的，计算时我们也需要对头部进行排序编码后进行计算 最后是请求体，最容易想到的是最常见提交表单请求，其内容和查询参数一样也是与顺序无关的查询字符串，那么请求体也需要对其处理吗？答案是否定的，尽管提交表单确实顺序无关的，但实际上协议并未对请求体内容做强制定义，比如我们可以带上二进制数据或者base64编码的数据等等。而且实际使用时请求体内容完全是由我们自己决定的。那么当请求体不同时，我们完全可以认为它是一个不同的请求了。 最终的请求指纹计算算法，用的是sha1哈希算法，sha1算法是安全散列标准（Secure Hash Standard）的第一个正式标准，后面还有第二三个版本的标准。目前sha1算法已经被破解，但对我们来说，我们的使用场景决定了我们并不关心使用sha1是否会被破解，因为我们并未用于加密数据。sha1相对于MD5算法碰撞概率已极大降低，而相对于后续版本的sha算法有着更快的计算速度，因此我们使用sha1算法作为我们计算请求指纹的哈希算法。 核心代码如下: import ( \"bytes\" \"crypto/sha1\" \"io\" \"io/ioutil\" \"net/http\" \"net/url\" \"sort\" \"strings\" ) // 规范化Url // 协议和域名部分不分大小写, 路径部分是否区分大小写则不一定, 要看具体网站后台是如何实现 // https://github.com/PuerkitoBio/purell 实现了更多的URL规范化规则 // See Python Package: w3lib.url.canonicalize_url func CanonicalizeUrl(u url.URL, keepFragment bool) url.URL { // 将query排序后重新保存 u.RawQuery = u.Query().Encode() // 确保即使没有RawQuery时的一致性 u.ForceQuery = true if !keepFragment { u.Fragment = \"\" } return u } // 计算请求指纹 func RequestFingerprint(r *http.Request, withHeader bool) []byte { sha := sha1.New() io.WriteString(sha, r.Method) u := CanonicalizeUrl(*r.URL, false) io.WriteString(sha, u.String()) if r.Body != nil { body, _ := r.GetBody() defer body.Close() b, _ := ioutil.ReadAll(body) sha.Write(b) } if withHeader { io.WriteString(sha, EncodeHeader(r.Header)) } return sha.Sum(nil) } // 对Header进行格式化, 可以用于输出Header和计算哈希 // https://tools.ietf.org/html/rfc2616#section-4.2 // The order in which header fields with differing field names are // received is not significant. However, it is \"good practice\" to send // general-header fields first, followed by request-header or response- // header fields, and ending with the entity-header fields. func EncodeHeader(h http.Header) string { if h == nil { return \"\" } var buf bytes.Buffer keys := make([]string, 0, len(h)) for k := range h { keys = append(keys, k) } // 对Header的键进行排序 sort.Strings(keys) for _, k := range keys { // 对值进行排序 buf.WriteString(k + \":\" + strings.Join(h[k], \";\") + \"\\n\") } return buf.String() } 实现上参考了Python中很出名的爬虫库Scrapy源码和它引用的w3lib库源码，有兴趣的可以通过下面的链接去查阅源码。 scrapy/utils/request.py#L19 w3lib/url.py#L425 ","date":"2017-03-29","objectID":"/http%E8%AF%B7%E6%B1%82%E6%8C%87%E7%BA%B9%E7%9A%84%E8%AE%A1%E7%AE%97/:2:0","tags":["HTTP","哈希"],"title":"HTTP请求指纹的计算","uri":"/http%E8%AF%B7%E6%B1%82%E6%8C%87%E7%BA%B9%E7%9A%84%E8%AE%A1%E7%AE%97/"},{"categories":["Python"],"content":"我一直使用嘀嗒清单做待办清单，它支持丰富的数据导入导出功能，强大的时间定义和日历功能，让我有了将它作为习惯和目标管理工具的想法。 因为之前有使用其数据导入功能添加个人课表的经验，所以这次我决定将我的扇贝打卡日历导出为ical文件再导入到嘀嗒清单。 既然是导出扇贝应用打卡日历，其核心就是使用一定的方式获取到我们所需要的数据。以往我们习惯的做法是通过网页爬虫解析页面得到我们所要抓取的数据，但对于有客户端的应用，我们首先应该想到的是对客户端数据进行抓包分析，一般就能够直接得到我们所需要的数据接口了。 在这里我使用的是Charles进行HTTP抓包。 我们首先打开Charles，在手机上注销掉扇贝单词的账号，设置网络代理用于抓包（如果手机没有安装Charles的根证书用于解密HTTPS需要先安装证书），然后填写我们的账号和密码进行登录抓包。 关于抓包及分析数据在这里我们就不做赘述了，基本接口在Charles显示的结果如下: 因为请求的内容有个人的敏感数据，实际的接口操作我们只需要看代码即可: # -*- coding:utf-8 -*- import logging import requests import icalendar from urllib.parse import urljoin from datetime import datetime def _init_logger(): logger = logging.Logger(\"shanbay\", logging.INFO) sh = logging.StreamHandler() # https://docs.python.org/3/library/logging.html#logrecord-attributes fmt = logging.Formatter('%(asctime)s[%(levelname)s]: %(message)s') sh.setFormatter(fmt) logger.addHandler(sh) return logger logger = _init_logger() class RequestError(Exception): pass class Shanbay: _base_url = \"https://rest.shanbay.com/\" def __init__(self, account, password): self.session = requests.Session() self._login(account, password) self.user = self.get_user_info() def _urljoin(self, path): return urljoin(self._base_url, path) @staticmethod def _check_response_status(response_json): \"\"\" 检查响应是否有错, 没有错误便返回data字段 \"\"\" if \"status_code\" not in response_json: raise RequestError(response_json[\"msg\"]) if response_json[\"status_code\"] != 0: raise RequestError( \"请求错误 {res[status_code]}: {res[msg]}\".format(res=response_json) ) return response_json[\"data\"] def _login(self, account, password): \"\"\" 登陆接口 :param account: 扇贝账号 :param password: 扇贝账号密码 :return: 登陆状态 \"\"\" # 直接登陆扇贝, 不存储用户名和密码 login_status = self.session.put( self._urljoin(\"api/v1/account/login/\"), json={ \"username\": account, \"password\": password } ).json() self._check_response_status(login_status) def get_user_info(self): \"\"\" 获取个人信息 \"\"\" user_info = self.session.get(self._urljoin(\"api/v1/common/user/\")).json() user_info = self._check_response_status(user_info) # 对用户信息做缓存用于得到接口的默认user_id参数 self.user = user_info return user_info def get_checkin_date(self): \"\"\" 获取当前打卡日期 \"\"\" checkin_date = self.session.get(self._urljoin(\"/api/v1/checkin/date/\")).json() return self._check_response_status(checkin_date) def get_checkins(self, year=None, month=None, user_id=None, v=3): \"\"\" 获取打卡日历 :param year: 年份, 不提供时为当前年份 :param month: 月份, 不提供时为当前月份 :param user_id: 用户ID, 不提供时为登陆用户id :param v: 返回的结果详细程度, 1 只返回相应日期是否打卡 3 返回相应日期的打卡id和打卡天数, 没打卡则为空 2 在 3 的基础上添加了分享相关的数据 \"\"\" d = datetime.today() if year is None: year = d.year if month is None: month = d.month if user_id is None: user_id = self.user[\"user_id\"] checkins = self.session.get( self._urljoin(\"api/v1/checkin/user/%s/\" % user_id), params={\"year\": year, \"month\": month, \"v\": v} ).json() checkins = self._check_response_status(checkins) return checkins def get_checkin_detail(self, checkin_id, user_id=None): \"\"\" 获取打卡详情 :param checkin_id: 打卡记录id :param user_id: 用户ID, 不提供时为登陆用户id \"\"\" if user_id is None: user_id = self.user[\"user_id\"] checkin_detail = self.session.get(self._urljoin(\"/api/v1/checkin/{}/{}/\".format(user_id, checkin_id))).json() checkin_detail = self._check_response_status(checkin_detail) return checkin_detail def export2ical(self, use_todo=True): \"\"\" 将打卡记录导出为ical :param use_todo: 是否使用 TODO 作为记录, false 时使用 Event 作为记录 :return: \"\"\" cls = icalendar.Todo if use_todo else icalendar.Event # https://zh.wikipedia.org/wiki/ICalendar # http://icalendar.readthedocs.io/en/latest # https://tools.ietf.org/html/rfc5545 cal = icalendar.Calendar() cal.add(\"X-WR-TIMEZONE\", self.get_checkin_date()[\"timezone\"]) cal.add('X-WR-CALNAME', \"{[nickname]}的扇贝打卡日历\".format(self.user)) d = datetime.today() year = d.year month = d.month # 扇贝 2011 才创立 day = (year - 2011 + 1) * 365 # 记录计数, 用于确认实际导出数量与服务器记录天数一致 count = 0 # 当打卡天数更新到第一天时表示所有记录已导出 while day != 1: logger.info(\"获取{}年{}月的打卡详情\".format(year, month)) checks = self.get_checkins(year, month) dates = sorted(checks.keys(), reverse=True) for c in checks.values(): # 没有打卡的天数内容为空 if not c: c","date":"2017-03-25","objectID":"/%E4%BD%BF%E7%94%A8python%E5%AF%BC%E5%87%BA%E6%89%87%E8%B4%9D%E5%BA%94%E7%94%A8%E6%89%93%E5%8D%A1%E6%97%A5%E5%8E%86/:0:0","tags":["扇贝","日历"],"title":"使用Python导出扇贝应用打卡日历","uri":"/%E4%BD%BF%E7%94%A8python%E5%AF%BC%E5%87%BA%E6%89%87%E8%B4%9D%E5%BA%94%E7%94%A8%E6%89%93%E5%8D%A1%E6%97%A5%E5%8E%86/"},{"categories":["Python"],"content":"Jupyter Notebook 介绍1 Jupyter Notebook 是一个基于提供了开发, 记录, 执行和展现结果等过程的Web应用. Jupyter Notebook 实现原理2 Jupyter Notebook 除了用于前端交互的 Web组件外, 其核心功能是与通过 IPython 内核通信实现的. ","date":"2016-11-25","objectID":"/jupyter-notebook-%E5%89%8D%E7%AB%AF%E4%BA%A4%E4%BA%92%E9%83%A8%E4%BB%B6%E5%AE%9E%E7%8E%B0/:0:0","tags":["Jupyter"],"title":"Jupyter Notebook 前端交互部件实现","uri":"/jupyter-notebook-%E5%89%8D%E7%AB%AF%E4%BA%A4%E4%BA%92%E9%83%A8%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Python"],"content":"IPython 内核 IPython 内核是一个提供了代码执行, 输入提示等功能的独立进程, 前端通过 ZeroMQ 套接字连接并使用 JSON 消息通信. ","date":"2016-11-25","objectID":"/jupyter-notebook-%E5%89%8D%E7%AB%AF%E4%BA%A4%E4%BA%92%E9%83%A8%E4%BB%B6%E5%AE%9E%E7%8E%B0/:1:0","tags":["Jupyter"],"title":"Jupyter Notebook 前端交互部件实现","uri":"/jupyter-notebook-%E5%89%8D%E7%AB%AF%E4%BA%A4%E4%BA%92%E9%83%A8%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Python"],"content":"Jupyter Notebook Jupyter Notebook 的实现添加了一个额外的服务中间件来完成消息的转发工作, 这样不仅能够提供本身文件管理方面的功能, 也使得其内核变成一个可替换的组件, 这也是为什么 Jupyter Notebook 能够作为多种语言前端的原因. Jupyter Notebook 交互部件的实现34 本质上, Jupyter Notebook 交互部件是一个特殊的 Jupyter Notebook 插件, 它的前端使用 JavaScript 编写, 后端逻辑由指定的内核语言编写, 在这里我们使用的是 Python, 因此我们直接继承 ipywidgets.DOMWidget 来完成核心逻辑的实现, 这里我们需要 traitlets 模块来帮我们完成前后端数据的同步. 基本结构如下: ","date":"2016-11-25","objectID":"/jupyter-notebook-%E5%89%8D%E7%AB%AF%E4%BA%A4%E4%BA%92%E9%83%A8%E4%BB%B6%E5%AE%9E%E7%8E%B0/:2:0","tags":["Jupyter"],"title":"Jupyter Notebook 前端交互部件实现","uri":"/jupyter-notebook-%E5%89%8D%E7%AB%AF%E4%BA%A4%E4%BA%92%E9%83%A8%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Python"],"content":"Python 代码 class FileUploadWidget(ipywidgets.DOMWidget): _view_name = traitlets.Unicode('FileUploadView').tag(sync=True) _view_module = traitlets.Unicode('fileupload').tag(sync=True) accept = traitlets.Unicode(help='Filetype acceptable.').tag(sync=True) filename = traitlets.Unicode(help='Filename of `data`.').tag(sync=True) data_base64 = traitlets.Unicode(help='File content, base64 encoded.').tag( sync=True) data = traitlets.Bytes(help='File content.') def __init__(self, accept, *args, **kwargs): super(FileUploadWidget, self).__init__(*args, **kwargs) self._dom_classes += ('widget_item', 'btn-group') self.accept = accept def _data_base64_changed(self, *args): self.data = base64.b64decode(self.data_base64.split(',', 1)[1]) 这个类中, 我们实现了一个名为 FileUploadWidget 的部件类, 其中 _view_name , _view_module 分别是用于说明与前端哪个模块中的哪个视图进行同步, 其他四个属性则是我们需要同步的属性. 其中, 比较特殊的是 data 属性, 由于我们上传文件使用的是 \u003cinput type=\"file\"/\u003e 标签, 然后利用浏览器接口 FileReader 读取文件内容, 而其内容是经过 base_64 编码的, 为了使用上的方便, 我们将前端读到的 base64 编码内容存到 data_base64 属性中, 再通过实现 _data_base64_changed 事件回调函数, 当文件内容发生变化时, 自动将 base64 编码内容转换为字节数组. ","date":"2016-11-25","objectID":"/jupyter-notebook-%E5%89%8D%E7%AB%AF%E4%BA%A4%E4%BA%92%E9%83%A8%E4%BB%B6%E5%AE%9E%E7%8E%B0/:3:0","tags":["Jupyter"],"title":"Jupyter Notebook 前端交互部件实现","uri":"/jupyter-notebook-%E5%89%8D%E7%AB%AF%E4%BA%A4%E4%BA%92%E9%83%A8%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Python"],"content":"JavaScript 代码 requirejs.undef('fileupload'); define('fileupload', ['jupyter-js-widgets'], function (widgets) { 'use strict'; let FileUploadView = widgets.DOMWidgetView.extend({ render: function render () { FileUploadView.__super__.render.apply(this, arguments); let element = document.createElement('input'); element.setAttribute('type', 'file'); element.setAttribute('accept', this.model.get('accept')); this.el.appendChild(element); if (/^image\\//.test(this.model.get('accept'))){ let img = document.createElement(\"img\"); img.setAttribute('id', 'uploadPreview'); img.setAttribute('width', '80%'); this.el.appendChild(img); } }, events: { 'change': '_handleFileChange' }, _handleFileChange: function _handleFileChange (ev) { let file = ev.target.files[0]; let that = this; if (file) { // https://developer.mozilla.org/zh-CN/docs/Web/API/FileReader let fileReader = new FileReader(); fileReader.onload = function fileReaderOnload (e) { that.model.set('data_base64', fileReader.result); that.touch(); let preview = document.getElementById(\"uploadPreview\"); if(preview !== null){ preview.src = e.target.result; } }; fileReader.readAsDataURL(file); } else { that.send({ ev: 'Unable to open file.' }); } that.model.set('filename', file.name); that.touch(); } }); return {FileUploadView: FileUploadView}; }); JavaScript 代码中, render 函数用于渲染前端页面, events 用于描述事件回调函数, 这里的基本逻辑就是当 \u003cinput/\u003e 标签中的文件路径值变化时重新读取文件内容. ","date":"2016-11-25","objectID":"/jupyter-notebook-%E5%89%8D%E7%AB%AF%E4%BA%A4%E4%BA%92%E9%83%A8%E4%BB%B6%E5%AE%9E%E7%8E%B0/:4:0","tags":["Jupyter"],"title":"Jupyter Notebook 前端交互部件实现","uri":"/jupyter-notebook-%E5%89%8D%E7%AB%AF%E4%BA%A4%E4%BA%92%E9%83%A8%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Python"],"content":"整合 我们把自带的部件和我们自己实现的部件结合在一起, 统一初始化便得到了最后的交互面板. class InteractPanel: def __init__(self): # 选择识别目标的部件 self.selection = ipywidgets.SelectMultiple( options=['Apples', 'Oranges', 'Pears'], value=['Oranges'], description='需要识别的目标选项', disabled=False) # 图片上传部件 self.image = FileUploadWidget(accept='image/*') # 开始计算部件 btn = ipywidgets.Button(description='开始', disabled=False) btn.on_click(self.on_button_click) # 交互面板部件 self.panel = ipywidgets.Tab( children=[self.image, ipywidgets.HBox([self.selection, btn])]) self.panel.set_title(0, '第一步') self.panel.set_title(1, '第二步') def on_button_click(self, button): # 点击开始按钮所进行的操作 # 保存文件 #with open('需要保存的文件路径', 'wb') as fp: # fp.write(self.image.data) # 获取选项 # value = self.selection.value # 执行 #!caffe 命令参数 pass def display(self): display(self.panel) 最终效果如: 第一步, 选择需要进行处理的图片, 第二步选择需要识别的目标, 然后点击开始按钮进行处理的工作. 整个过程只显示了一个交互面板, 同时满足的美观性和实用性的要求. http://jupyter-notebook.readthedocs.io/en/latest/notebook.html#introduction ↩︎ http://jupyter.readthedocs.io/en/latest/architecture/how_jupyter_ipython_work.html#how-ipython-and-jupyter-notebook-work ↩︎ https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Custom.html ↩︎ https://github.com/peteut/ipython-file-upload ↩︎ ","date":"2016-11-25","objectID":"/jupyter-notebook-%E5%89%8D%E7%AB%AF%E4%BA%A4%E4%BA%92%E9%83%A8%E4%BB%B6%E5%AE%9E%E7%8E%B0/:5:0","tags":["Jupyter"],"title":"Jupyter Notebook 前端交互部件实现","uri":"/jupyter-notebook-%E5%89%8D%E7%AB%AF%E4%BA%A4%E4%BA%92%E9%83%A8%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"摘要 Linux 是一个是一个基于 POSIX 和 UNIX 的多用户、多任务、支持多线程和多 CPU 的操作系统。 多用户的设计让系统变得高效而安全，而在各种领域的应用也越来越广泛。 Linux 的核心思想之一便是认为一切皆为文件，本文从 Linux 文件的概念出发，探讨了 Linux 文件权限设计以及其在系统安全上的重要意义。 ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:1:0","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux"],"content":"1. Linux 下文件的概念 Linux 的基本思想之一就是一切皆为文件，通过不同的文件种类和属性来描述数据，程序或者设备。 ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:2:0","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux"],"content":"1.1 Linux 文件种类与扩展名 Linux 中有六种文件类型，注意文件类型并不是 Windows 中文件格式的概念。 正规文件 (regular file)： 就是一般我们在进行存取的类型的文件，依照文件的内容，又大略可以分为： 纯文本文件 (ASCII)：Linux 系统中最多的一种文件类型，其内容为我们人类可以直接读到的数据，例如数字、字母等等。 二进制文件 (binary)：包含在 ASCII 及扩展 ASCII 字符中编写的数据或程序指令的文件。 数据格式文件 (data)：有些程序在运作的过程当中会读取某些特定格式的文件，那些特定格式的文件可以被称为数据文件 (data file)。 目录 (directory) 连结文件 (link)：类似 Windows 系统中的快捷方式，用于指向某个文件。 设备与装置文件 (device)：与系统周边及储存等相关的一些文件，通常都集中在 /dev 这个目录之下。通常又分为两种： 区块 (block) 设备文件：数据储存，以提供系统随机存取的接口设备，例如硬盘与软 盘。 字符 (character) 设备文件：一些串行端口的接口设备，例如键盘、鼠标等。 数据接口文件 (sockets)：用于网络上的数据承接。 数据输送文件 (FIFO,pipe)：FIFO 是 first-in-first-out 的缩写。主要的目的在解决多个程序同时存取一个文件所造成的错误问题。 文件对应的类型通过以下符号来进行表示： 文件类型 类型符号 正规文件 (regular file) - 目录 (directory) d 连结文件 (link) l 区块 (block) 设备文件 b 字符 (character) 设备文件 c 数据接口文件 (sockets) s 数据输送文件 (FIFO,pipe) p ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:2:1","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux"],"content":"2. Linux 文件权限概念 Linux 文件权限设计简洁而又实用，对于每个授权对象，基本的权限属性有 r , w , x ，还有一些不常见的隐藏属性或权限。 ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:3:0","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux"],"content":"2.1 使用者与群组 Linux 文件针对的授权对象有三种类型，分为文件拥有者（Owner），群组（Group）与其他（Other）。 ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:3:1","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux"],"content":"2.2 权限对文件的重要性 文件是实际含有数据的地方，包括一般文本文件、数据库内容文件、二进制可执行文件(binary program) 等等。 因此，权限对于文件来说，他的意义是这样的： r (read)：可读取此一文件的实际内容，如读取文本文件的文字内容等； w (write)：可以编辑、新增或者是修改该文件的内容 (但不含删除该文件)； x (execute)：该文件具有可以被系统执行的权限。 需要注意的是，在 Windows 中一个文件是否具有执行的能力是由 “文件扩展名” 来判断的，例如：.exe, .bat, .com 等等， 但是在 Linux 中，文件能否被执行，则是由是否具有 x 这个权限来决定的，与文件名没有绝对的关系。 而对于 w 权限，当拥有 w 权限时，权限拥有者可以对文件的内容进行写入/编辑/新增/修改操作，但并不具备有删除该文件本身的权限。 也就是说文件权限，主要都是针对 “文件的内容” 而言的，与文件档名的存在与否没有关系。 ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:3:2","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux"],"content":"2.3 权限对目录的重要性 目录主要的内容在记录文件名列表，文件名与目录有强烈的关联。 r (read contents in directory)：表示具有读取目录结构列表的权限 w (modify contents of directory)：表示具有修改目录结构列表的权限，例如: 建立新的文件与目录； 删除已经存在的文件与目录 (不论该文件的权限为何！) 将已存在的文件或目录进行更名； 搬移该目录内的文件、目录位置。 x (access directory)：代表的是用户能否进入该目录成为工作目录。 ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:3:3","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux"],"content":"3. 文件与目录的默认权限 在 Linux 中，root 用户登录系统建立文件和目录的访问权限分别为 644 和 755； 普通用户登陆，建立文件和目录的访问权限分别为 664 和 775， 两类两类用户建立的文件和目录访问权限不同，与 Linux 的权限掩码有关。 为了提高文件系统的安全性, 方便用户权限设置, Linux 设置了权限掩码（umask）， root 用户和普通用户登录系统，权限掩码默认分别为 022 和 002。 在不考虑权限掩码的情况下，Linux 约定新建文件和目录的权限为 666 和 777，称为 “约定权限”。 在系统给定权限掩码的情况下, 新建文件和目录的访问权限为文件和目录的约定权限与权限掩码值取反后作逻辑与运算, 得到文件和\u000c目录的访问权限。 ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:4:0","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux"],"content":"4. 文件隐藏属性 Linux 文件的隐藏属性更多的是提供一些功能上的支持，但是合适地配置这些属性能极大地提高系统的安全性。 A ：当配置了 A 这个属性时，若你有存取此文件 (或目录) 时，他的存取时间 atime 将不会被修改，可避免 I/O 较慢的机器过度的存取磁碟。这对速度较慢的计算机有帮助。 S ：一般文件是非同步写入磁碟的，如果加上 S 这个属性时，当你进行任何文件的修改，该更动会『同步』写入磁碟中。 a ：当配置 a 之后，这个文件将只能添加数据，而不能删除也不能修改数据，只有 root 才能配置这个属性。 c ：这个属性配置之后，将会自动的将此文件『压缩』，在读取的时候将会自动解压缩，但是在储存的时候，将会先进行压缩后再储存。 d ：当 dump 程序被运行的时候，配置 d 属性将可使该文件 (或目录) 不会被 dump 备份。 i ：让一个文件不能被删除、改名、配置连结也无法写入或新增数据，只有 root 能配置此属性。 s ：当文件配置了 s 属性时，如果这个文件被删除，将会被完全的移除出这个硬盘空间。 u ：与 s 相反，当使用 u 来配置文件时，如果该文件被删除，则数据内容其实还存在磁碟中。 ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:5:0","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux"],"content":"5. 文件特殊权限： SUID, SGID, SBIT Linux 文件的特殊权限能够解决一些特殊的文件操作场景中遇到的问题，例如使用 passwd 程序修改用户密码时的权限问题。 一般情况下并不需要对文件设置这些特殊权限。 ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:6:0","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux"],"content":"Set UID 当 s 这个标志出现在文件拥有者的 x 权限上时，此时就被称为 Set UID ，简称为 SUID 的特殊权限。 SUID 有这样的限制与功能： SUID 权限仅对二进位程序 (binary program) 有效； 运行者对於该程序需要具有 x 的可运行权限； 本权限仅在运行该程序的过程中有效 (run-time)； 运行者将具有该程序拥有者 (owner) 的权限。 ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:6:1","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux"],"content":"Set GID 当 s 标志在群组的 x 时则称为 Set GID , 简称为 SGID 。与 SUID 不同的是， SGID 可以针对文件或目录来配置。 如果是对文件来说， SGID 有如下的功能： SGID 对二进位程序有用； 程序运行者对於该程序来说，需具备 x 的权限； 运行者在运行的过程中将会获得该程序群组的支持。 当一个目录配置了 SGID 的权限后，他将具有如下的功能： 使用者若对于此目录具有 r 与 x 的权限时，该使用者能够进入此目录； 使用者在此目录下的有效群组 (effective group) 将会变成该目录的群组； 用途：若使用者在此目录下具有 w 的权限 (可以新建文件)，则使用者所创建的新文件，该新文件的群组与此目录的群组相同。 ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:6:2","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux"],"content":"Sticky Bit Sticky Bit 简称 SBIT ，目前只针对目录有效其作用是： 当使用者对于此目录具有 w , x 权限，也就是具有写入的权限时； 当使用者在该目录下创建文件或目录时，仅有自己与 root 才有权力删除该文件。 ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:6:3","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":["Linux"],"content":"6. 总结 Linux 将一切视为文件的思想与其简洁实用的权限设计，搭配上用户角色与群组系统，使整个系统的安全性大大的提升，同时也让它成为了优秀的多用户多任务系统，通过对 Linux 文件权限的设计，能够加深我们对系统安全的理解。 ","date":"2016-05-23","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/:7:0","tags":["Linux"],"title":"Linux 文件权限系统探究","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E6%8E%A2%E7%A9%B6/"},{"categories":[],"content":"背景 数字编码指的是把数字形式的数据以数字信号方式在信道上传输的技术。最简单的想法就是使用非归零编码（NRZ， 正电压为 1， 负电压为 0），但是由于在数据通信中发送方和接收方的时钟无法精确同步，时钟漂移 问题会使数据传送发生错误。 另外，接受方通过将当前接收到的信号与之前接收的信号的平均值进行比较判断接收的比特是 0 还是 1，但是传输的比特为连续的 1 或 0 时就会改变这个平均这，产生 基线漂移。 为了解决这些问题，一系列编码方式开始产生，包括 非归零反转 编码，曼彻斯特 编码 差分曼彻斯特 编码等等，同时为了提升传输效率又产生了 4B/5B 编码和 MLT-3 编码。 ","date":"2015-10-18","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BF%A1%E9%81%93%E7%9A%84%E6%95%B0%E5%AD%97%E7%BC%96%E7%A0%81/:1:0","tags":["计算机网络"],"title":"计算机网络信道的数字编码","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BF%A1%E9%81%93%E7%9A%84%E6%95%B0%E5%AD%97%E7%BC%96%E7%A0%81/"},{"categories":[],"content":"各个编码的特征 非归零编码 特征： 高 1 低 0 优点： 简单 缺点： 抗干扰能力极差，实际不使用这种编码 非归零反转编码 特征： 差分编码，1 跳 0 不跳 优点： 抗干扰能力更强 缺点： 编解码更复杂，对连续为 0 的情况无能为力 曼彻斯特编码 特征： 自同步，每个比特跳变一次且 1，0 对应的跳变是不变的 优点： 能够保持通信同步 缺点： 编码效率低，只有 50% 差分曼彻斯特编码 特征： 差分编码，比特开始时，有跳为 0，无跳为 1 优点： 能够保持通信同步 缺点： 编码效率低，只有 50% 4B/5B 编码 特征： 将数据以 4 比特为一组进行分割并映射为 5 比特码组 优点： 保持通信同步的同时将效率提高到 80% 缺点： 直接用在 100Mbps 的双绞线可能会因带宽不够出现问题 MLT-3 编码 特征：差分编码，0 不跳 1 跳反 优点：4 比特对应一个信号模式（-V，0，+V，0） 缺点：最坏情况下，信号波特率为数据速率的 1/4 ","date":"2015-10-18","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BF%A1%E9%81%93%E7%9A%84%E6%95%B0%E5%AD%97%E7%BC%96%E7%A0%81/:2:0","tags":["计算机网络"],"title":"计算机网络信道的数字编码","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BF%A1%E9%81%93%E7%9A%84%E6%95%B0%E5%AD%97%E7%BC%96%E7%A0%81/"},{"categories":[],"content":"编码规则 编码规则我使用了 Python 进行实现，为了使规则简单易懂，没有对函数进一步抽象，同时进行了注释有助于理解。 另外 4B/5B 编码为简单的映射编码，十分简单，编写冗长的映射表没有意义，故不作实现。 以下为实现代码： HIGH_LEVEL_SIGNAL = 1 LOW_LEVEL_SIGNAL = 0 NEGATIVE_HIGH_LEVEL_SIGNAL = -1 def nrz(signal): \"\"\" 非归零编码 \"\"\" return signal def nrzi(signal): \"\"\" 非归零反转编码, 1 跳变, 0 不跳变. \"\"\" prev = LOW_LEVEL_SIGNAL result = [] for v in signal: if v == HIGH_LEVEL_SIGNAL: if prev == HIGH_LEVEL_SIGNAL: v = LOW_LEVEL_SIGNAL elif prev == LOW_LEVEL_SIGNAL: v = HIGH_LEVEL_SIGNAL elif v == LOW_LEVEL_SIGNAL: v = prev result.append(v) prev = v return result def pe(signal): \"\"\" 曼彻斯特编码(Manchester Encoding), 也叫做相位编码(Phase Encode,简写PE) 关于中间电平跳变观点有歧义: 第一种 G. E. Thomas, Andrew S. Tanenbaum1949年提出的, 它规定0是由低-高的电平跳变表示, 1是高-低的电平跳变. 第二种 IEEE 802.4(令牌总线)和低速版的IEEE 802.3(以太网)中规定, 按照这样的说法, 低-高电平跳变表示1, 高-低的电平跳变表示0. 由于有以上两种不同的表示方法, 所以有些地方会出现歧异. 当然, 这可以在差分曼彻斯特编码(Differential Manchester encoding)方式中克服. 样例程序使用第一种观点. \"\"\" result = [] for v in signal: if v == HIGH_LEVEL_SIGNAL: v = [1, 0] elif v == LOW_LEVEL_SIGNAL: v = [0, 1] result.extend(v) return result def cdp(signal, reverse_start=False): \"\"\" 差分曼彻斯特编码又叫条件双相码(CDP码). 主要看两个相邻的波形,如果后一个波形和前一个的波形相同,则后一个波形表示0,如果波形不同,则表示1. [注意]:如果在最初信号的时候,即第一个信号时(IEEE 802.3标准): 如果中间位电平从低到高,则表示0； 如果中间位电平从高到低,则表示1； \"\"\" first = signal[0] if first == HIGH_LEVEL_SIGNAL: first = [1, 0] elif first == LOW_LEVEL_SIGNAL: first = [0, 1] if reverse_start: first.reverse() prev = first result = [] result.extend(prev) for v in signal[1:]: if v == HIGH_LEVEL_SIGNAL: # 无跳变表示1, 波形与前一个相反 prev.reverse() v = prev elif v == LOW_LEVEL_SIGNAL: # 有跳变表示0, 波形与前一个相同 v = prev result.extend(v) return result def mlt_3(signal): \"\"\" MLT-3 编码 1.如果下一比特是0，则输出值与前面的值相同； 2.如果下一比特是1，则输出值就要有一个转变： 如果前面输出的值是+V或-V，则下一输出为0；如果前面输出的值是0，则下一输出的值与上一个非0值符号相反 \"\"\" last_nonzero = LOW_LEVEL_SIGNAL prev = HIGH_LEVEL_SIGNAL result = [] for v in signal: if v == HIGH_LEVEL_SIGNAL: if prev != LOW_LEVEL_SIGNAL: v = LOW_LEVEL_SIGNAL else: if last_nonzero == LOW_LEVEL_SIGNAL: v = NEGATIVE_HIGH_LEVEL_SIGNAL elif last_nonzero == NEGATIVE_HIGH_LEVEL_SIGNAL: v = HIGH_LEVEL_SIGNAL last_nonzero = v elif v == LOW_LEVEL_SIGNAL: # 为0则波形与前一个相同 v = prev result.append(v) prev = v return result if __name__ == \"__main__\": signal = list(map(int, \"011000101111\")) print('非归零编码:', nrz(signal)) print('非归零反转编码:', nrzi(signal)) print('曼彻斯特编码:', pe(signal)) print('差分曼彻斯特编码:', cdp(signal)) print('MLT-3 编码:', mlt_3(signal)) from pylab import * x = range(0, len(signal) + 1) x2 = range(0, len(signal) * 2 + 1) y = signal subplot(511) nrz_result = nrz(signal) # 非归零编码 title(\"nrz\") axis([0, len(x), -0.2, 1.2]) grid(True) frame = gca() frame.axes.get_xaxis().set_visible(False) frame.axes.get_yaxis().set_visible(False) step(x, nrz_result[:1] + nrz_result, label=\"nrz\") subplot(512) nrzi_result = nrzi(signal) # 非归零反转编码 title(\"nrzi\") axis([0, len(x), -0.2, 1.2]) grid(True) frame = gca() frame.axes.get_xaxis().set_visible(False) frame.axes.get_yaxis().set_visible(False) step(x, nrzi_result[:1] + nrzi_result, label=\"nrzi\") subplot(513) pe_result = pe(signal) # 曼彻斯特编码 title(\"pe\") axis([0, len(x2), -0.2, 1.2]) grid(True) frame = gca() frame.axes.get_xaxis().set_visible(False) frame.axes.get_yaxis().set_visible(False) step(x2, pe_result[:1] + pe_result, label=\"pe\") subplot(514) cdp_result = cdp(signal, reverse_start=True) # 差分曼彻斯特编码 title(\"cdp\") axis([0, len(x2), -0.2, amax(y) * 1.2]) grid(True) frame = gca() frame.axes.get_xaxis().set_visible(False) frame.axes.get_yaxis().set_visible(False) step(x2, cdp_result[:1] + cdp_result, label=\"cdp\") subplot(515) mlt_3_result = mlt_3(signal) # MLT-3编码 title(\"mlt_3\") axis([0, len(x), -1.2, amax(y) * 1.2]) grid(True) frame = gca() frame.axes.get_xaxis().set_visible(False) frame.axes.get_yaxis().set_visible(False) step(x, mlt_3_result[:1] + mlt_3_result, label=\"mlt_3\") subplots_adjust(hspace=0.5) show() 输出结果： 非归零编码: [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1] 非归零反转编码: [0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1] 曼彻斯特编码: [0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0] 差分曼彻斯特编码: [0, 1, 1, 0, ","date":"2015-10-18","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BF%A1%E9%81%93%E7%9A%84%E6%95%B0%E5%AD%97%E7%BC%96%E7%A0%81/:3:0","tags":["计算机网络"],"title":"计算机网络信道的数字编码","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BF%A1%E9%81%93%E7%9A%84%E6%95%B0%E5%AD%97%E7%BC%96%E7%A0%81/"}]